{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "440825f3",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-18T20:10:35.308186Z",
     "iopub.status.busy": "2025-06-18T20:10:35.307899Z",
     "iopub.status.idle": "2025-06-18T20:10:35.383759Z",
     "shell.execute_reply": "2025-06-18T20:10:35.382803Z"
    },
    "papermill": {
     "duration": 0.093368,
     "end_time": "2025-06-18T20:10:35.384921",
     "exception": true,
     "start_time": "2025-06-18T20:10:35.291553",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19/3116054837.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mUnetArhitecture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;31m#Encoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class UnetArhitecture(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        #Encoder\n",
    "        self.e1 = nn.Sequential(\n",
    "            nn.Conv2d(3,64,3,padding=1),nn.BatchNorm2d(64),nn.ReLU(),\n",
    "            nn.Conv2d(64,64,3,padding=1),nn.BatchNorm2d(64),nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.max_pooling_e1 = nn.MaxPool2d(2) \n",
    "        \n",
    "        self.e2 = nn.Sequential(\n",
    "            nn.Conv2d(64,128,3,padding=1),nn.BatchNorm2d(128),nn.ReLU(),\n",
    "            nn.Conv2d(128,128,3,padding=1),nn.BatchNorm2d(128),nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.max_pooling_e2 = nn.MaxPool2d(2) \n",
    "        \n",
    "        self.e3 = nn.Sequential(\n",
    "            nn.Conv2d(128,256,3,padding=1),nn.BatchNorm2d(256),nn.ReLU(),\n",
    "            nn.Conv2d(256,256,3,padding=1),nn.BatchNorm2d(256),nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        #BottleNeck\n",
    "        self.max_pooling_e3 = nn.MaxPool2d(2)\n",
    "        self.bottle_neck = nn.Sequential(\n",
    "            nn.Conv2d(256,512,3,padding=1),nn.BatchNorm2d(512),nn.ReLU(),\n",
    "            nn.Conv2d(512,512,3,padding=1),nn.BatchNorm2d(512),nn.ReLU(),\n",
    "            nn.ConvTranspose2d(512, 256, 2, stride=2)\n",
    "        )\n",
    "    \n",
    "        self.d3 = nn.Sequential(\n",
    "            nn.Conv2d(512,256,3,padding=1),nn.BatchNorm2d(256),nn.ReLU(), #at this part concat with e3 (256 from e3 + 256 from bottle_neck)\n",
    "            nn.Conv2d(256,256,3,padding=1),nn.BatchNorm2d(256),nn.ReLU(),\n",
    "            nn.ConvTranspose2d(256, 128, 2, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.d2 = nn.Sequential(\n",
    "            nn.Conv2d(256,128,3,padding=1),nn.BatchNorm2d(128),nn.ReLU(), #at this part concat with e2 (128 from e2 + 128 from d3)\n",
    "            nn.Conv2d(128,128,3,padding=1),nn.BatchNorm2d(128),nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.d1 = nn.Sequential(\n",
    "            nn.Conv2d(128,64,3,padding=1),nn.BatchNorm2d(64),nn.ReLU(), #at this part concat with e1 (64 from e1 + 64 from d2)\n",
    "            nn.Conv2d(64,64,3,padding=1),nn.BatchNorm2d(64),nn.ReLU(),\n",
    "            nn.Conv2d(64, 1, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #print(\"Input:\", x.shape)\n",
    "        e1 = self.e1(x)\n",
    "        #print(\"e1:\", e1.shape)\n",
    "        e2 = self.e2(self.max_pooling_e1(e1))\n",
    "        #print(\"e2:\", e2.shape)\n",
    "        e3 = self.e3(self.max_pooling_e2(e2))\n",
    "        #print(\"e3:\", e3.shape)\n",
    "        bottle_neck = self.bottle_neck(self.max_pooling_e3(e3))\n",
    "        #print(\"bottleneck:\", bottle_neck.shape)\n",
    "        d3 = self.d3(torch.cat([e3, bottle_neck], dim=1))\n",
    "        #print(\"d3:\", d3.shape)\n",
    "        d2 = self.d2(torch.cat([e2, d3], dim=1))\n",
    "        #print(\"d2:\", d2.shape)\n",
    "        d1 = self.d1(torch.cat([e1, d2], dim=1))\n",
    "        #print(\"d1 / Output:\", d1.shape)\n",
    "        return d1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be81b75e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T12:12:25.408294Z",
     "iopub.status.busy": "2025-06-17T12:12:25.408019Z",
     "iopub.status.idle": "2025-06-17T12:13:48.065006Z",
     "shell.execute_reply": "2025-06-17T12:13:48.063971Z",
     "shell.execute_reply.started": "2025-06-17T12:12:25.408273Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q monai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4393e4eb",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-17T12:13:57.012188Z",
     "iopub.status.busy": "2025-06-17T12:13:57.011838Z",
     "iopub.status.idle": "2025-06-17T12:14:00.778060Z",
     "shell.execute_reply": "2025-06-17T12:14:00.777320Z",
     "shell.execute_reply.started": "2025-06-17T12:13:57.012160Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install segmentation-models-pytorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0cc957",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T12:14:09.147288Z",
     "iopub.status.busy": "2025-06-17T12:14:09.146502Z",
     "iopub.status.idle": "2025-06-17T12:14:45.041364Z",
     "shell.execute_reply": "2025-06-17T12:14:45.040748Z",
     "shell.execute_reply.started": "2025-06-17T12:14:09.147257Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch.nn.functional as F\n",
    "from monai.losses import DiceLoss\n",
    "from monai.losses import HausdorffDTLoss\n",
    "from monai.metrics import compute_average_surface_distance\n",
    "from PIL import Image \n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import seaborn as sns\n",
    "from torch.utils.data import Dataset\n",
    "from segmentation_models_pytorch.losses import FocalLoss\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "class CellDataSet:\n",
    "    def __init__(self, batch_size=1):\n",
    "        self.batch_size = batch_size\n",
    "        self.path = \"/kaggle/input/celldetection/ds1\"\n",
    "        self.test_path = os.path.join(self.path, \"test\")\n",
    "        self.train_path = os.path.join(self.path, \"train\")\n",
    "        self.validation_path = os.path.join(self.path, \"validation\")\n",
    "\n",
    "        self.img_path = \"img/cls\"\n",
    "        self.bin_mask_path = \"bin_mask/cls\"\n",
    "        self.multi_mask_path = \"mult_mask/cls\"\n",
    "\n",
    "        self.train = os.listdir(os.path.join(self.train_path, self.img_path))\n",
    "        self.test = os.listdir(os.path.join(self.test_path, self.img_path))\n",
    "\n",
    "        self.current_index = 0\n",
    "        self.indices = random.sample(self.train, len(self.train))\n",
    "\n",
    "\n",
    "    def load_sample(self, base_path, img_id, grayscale = False, scharr = False):\n",
    "        try:\n",
    "            image = Image.open(os.path.join(base_path, self.img_path, img_id))\n",
    "            if not grayscale:\n",
    "                image = image.convert(\"RGB\")\n",
    "                image = torch.tensor(np.array(image), dtype=torch.float32).permute(2, 0, 1) / 255.0\n",
    "            else:\n",
    "                image = image.convert(\"L\")\n",
    "                image_np = np.array(image)\n",
    "                if scharr:\n",
    "                    # Apply Scharr edge detection\n",
    "                    scharr_x = cv2.Scharr(image_np, cv2.CV_32F, 1, 0)\n",
    "                    scharr_y = cv2.Scharr(image_np, cv2.CV_32F, 0, 1)\n",
    "                    magnitude = cv2.magnitude(scharr_x, scharr_y)\n",
    "                    magnitude = cv2.normalize(magnitude, None, 0, 1, cv2.NORM_MINMAX)\n",
    "                    image = torch.tensor(magnitude, dtype=torch.float32).unsqueeze(0)\n",
    "                else:\n",
    "                    image = torch.tensor(image_np, dtype=torch.float32).unsqueeze(0) / 255.0\n",
    "            bin_mask = Image.open(os.path.join(base_path, self.bin_mask_path, img_id)).convert(\"L\")\n",
    "            mult_mask = Image.open(os.path.join(base_path, self.multi_mask_path, img_id))\n",
    "            bin_mask = torch.tensor(np.array(bin_mask), dtype=torch.float32).unsqueeze(0) / 255.0\n",
    "            mult_mask = torch.tensor(np.array(mult_mask), dtype=torch.long)\n",
    "\n",
    "            return image, bin_mask, mult_mask\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Failed to load sample '{img_id}' from {base_path}: {e}\")\n",
    "            return None, None, None\n",
    "\n",
    "    def get_train_index(self, index, grayscale = False, scharr = False):\n",
    "        img_id = self.train[index]\n",
    "        return self.load_sample(self.train_path, img_id, grayscale = grayscale)\n",
    "\n",
    "    def get_test_index(self, index, grayscale = False, scharr = False):\n",
    "        img_id = self.test[index]\n",
    "        return self.load_sample(self.test_path, img_id,  grayscale = grayscale, scharr = scharr)\n",
    "\n",
    "    def get_validation_by_name(self, name, grayscale = False, scharr = False):\n",
    "        return self.load_sample(self.validation_path, name,  grayscale = grayscale, scharr = scharr)\n",
    "\n",
    "    def apply_augmentations(self, sample):\n",
    "        image, bin_mask, mult_mask = sample\n",
    "        choice = random.choice([\"hflip\", \"vflip\", \"rotate\"])\n",
    "        if choice == \"hflip\":\n",
    "            image = TF.hflip(image)\n",
    "            bin_mask = TF.hflip(bin_mask)\n",
    "            mult_mask = TF.hflip(mult_mask)\n",
    "        elif choice == \"vflip\":\n",
    "            image = TF.vflip(image)\n",
    "            bin_mask = TF.vflip(bin_mask)\n",
    "            mult_mask = TF.vflip(mult_mask)\n",
    "        elif choice == \"rotate\":\n",
    "            angle = random.uniform(-15, 15)\n",
    "            image = TF.rotate(image, angle, fill=0)\n",
    "            bin_mask = TF.rotate(bin_mask, angle, fill=0)\n",
    "            if mult_mask.ndim == 2:\n",
    "                mult_mask = mult_mask.unsqueeze(0)  # [1, H, W]\n",
    "            mult_mask = TF.rotate(mult_mask, angle, fill=0)\n",
    "            mult_mask = mult_mask.squeeze(0)\n",
    "\n",
    "        return image, bin_mask, mult_mask\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981b86ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T04:35:31.649567Z",
     "iopub.status.busy": "2025-06-17T04:35:31.648870Z",
     "iopub.status.idle": "2025-06-17T04:35:31.662880Z",
     "shell.execute_reply": "2025-06-17T04:35:31.662252Z",
     "shell.execute_reply.started": "2025-06-17T04:35:31.649544Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "def train_model(model, dataset, num_epochs=10, device=\"cuda\", grayscale=False,  scharr = False,\n",
    "                patience=10,  scale_factor=1, save_path=\"best_model.pth\"):\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "    \n",
    "\n",
    "    def compute_loss(output, bin_mask):\n",
    "        #focal_loss = FocalLoss('binary') \n",
    "        #bce = torch.nn.BCEWithLogitsLoss()\n",
    "        dice_loss = DiceLoss(sigmoid=True)\n",
    "        #hausdorff_loss= HausdorffDTLoss(sigmoid=True)\n",
    "        #haus = hausdorff_loss(output, bin_mask) \n",
    "        return dice_loss(output,bin_mask) #0.5 * focal_loss(output,bin_mask) +  + 0.00002 * haus\n",
    "           \n",
    "    val_img_dir = os.path.join(dataset.validation_path, dataset.img_path)\n",
    "    val_filenames = sorted(os.listdir(val_img_dir))\n",
    "    best_val_loss = float(\"inf\")\n",
    "    epochs_without_improvement = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\n=== Epoch {epoch+1}/{num_epochs} ===\")\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        batch_count = 0\n",
    "\n",
    "        for idx in range(len(dataset.train)):\n",
    "            # --- Original sample ---\n",
    "            image, bin_mask, _ = dataset.get_train_index(idx, grayscale=grayscale, scharr=scharr)\n",
    "            if image is None:\n",
    "                continue\n",
    "\n",
    "            orig_size = image.shape[-2:]  # Save original size\n",
    "\n",
    "            if scale_factor != 1:\n",
    "                image = F.interpolate(image.unsqueeze(0), scale_factor=1/scale_factor, mode='bilinear', align_corners=False)\n",
    "            else:\n",
    "                image = image.unsqueeze(0)\n",
    "            \n",
    "            bin_mask = bin_mask.unsqueeze(0)\n",
    "\n",
    "            image = image.to(device)\n",
    "            bin_mask = bin_mask.to(device)\n",
    "\n",
    "            outputs = model(image)\n",
    "\n",
    "            if scale_factor != 1:\n",
    "                outputs = F.interpolate(outputs, size=orig_size, mode='bilinear', align_corners=False)\n",
    "            \n",
    "            loss = compute_loss(outputs, bin_mask)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            batch_count += 1\n",
    "\n",
    "            # --- Augmented sample ---\n",
    "            aug_image, aug_bin_mask, _ = dataset.apply_augmentations(\n",
    "                dataset.get_train_index(idx, grayscale=grayscale, scharr=scharr)\n",
    "            )\n",
    "\n",
    "            orig_size = aug_image.shape[-2:]  # Save original size\n",
    "\n",
    "            if scale_factor != 1:\n",
    "                aug_image = F.interpolate(aug_image.unsqueeze(0), scale_factor=1/scale_factor, mode='bilinear', align_corners=False)\n",
    "            else:\n",
    "                aug_image = aug_image.unsqueeze(0)\n",
    "\n",
    "            aug_bin_mask = aug_bin_mask.unsqueeze(0).to(device)\n",
    "\n",
    "            aug_image = aug_image.to(device)\n",
    "\n",
    "            outputs = model(aug_image)\n",
    "            if scale_factor != 1:\n",
    "                outputs = F.interpolate(outputs, size=orig_size, mode='bilinear', align_corners=False)\n",
    "            loss = compute_loss(outputs, aug_bin_mask)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            batch_count += 1\n",
    "\n",
    "            #if batch_count % 5 == 0:\n",
    "            #    print(f\"  [Train] Batch {batch_count} - Loss: {loss.item():.4f}\")\n",
    "\n",
    "        avg_train_loss = running_loss / batch_count\n",
    "        print(f\"[Train] Epoch {epoch+1} avg loss: {avg_train_loss:.4f}\")\n",
    "        gc.collect()\n",
    "        # === Validation ===\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for name in val_filenames:\n",
    "                image, bin_mask, _ = dataset.get_validation_by_name(name, grayscale=grayscale)\n",
    "                if image is None:\n",
    "                    continue\n",
    "\n",
    "                orig_size = image.shape[-2:]\n",
    "\n",
    "                if scale_factor != 1:\n",
    "                    image = F.interpolate(image.unsqueeze(0), scale_factor=1/scale_factor, mode='bilinear', align_corners=False)\n",
    "                else:\n",
    "                    image = image.unsqueeze(0)\n",
    "                bin_mask = bin_mask.unsqueeze(0)\n",
    "                \n",
    "                image = image.to(device)\n",
    "                bin_mask = bin_mask.to(device)\n",
    "\n",
    "                output = model(image)\n",
    "\n",
    "                if scale_factor != 1:\n",
    "                    output = F.interpolate(output, size=orig_size, mode='bilinear', align_corners=False)\n",
    "                \n",
    "                loss = compute_loss(output, bin_mask)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_filenames)\n",
    "        print(f\"[Validation] Epoch {epoch+1} avg loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "        # === Early Stopping ===\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            print(\"✅ Validation loss improved — saving model.\")\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            epochs_without_improvement = 0\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "            print(f\"No improvement ({epochs_without_improvement}/{patience} patience).\")\n",
    "            if epochs_without_improvement >= patience:\n",
    "                print(\"🛑 Early stopping triggered.\")\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41f1db6",
   "metadata": {
    "execution": {
     "execution_failed": "2025-05-21T06:55:00.366Z",
     "iopub.execute_input": "2025-05-21T06:54:52.531714Z",
     "iopub.status.busy": "2025-05-21T06:54:52.531484Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print(\"Before Dataset: {:.2f} MB\".format(torch.cuda.memory_allocated() / 1024**2))\n",
    "dataset = CellDataSet(batch_size=2)\n",
    "#print(\"Before Unet: {:.2f} MB\".format(torch.cuda.memory_allocated() / 1024**2))\n",
    "model = UnetArhitecture()\n",
    "#print(\"By start Memory Allocated: {:.2f} MB\".format(torch.cuda.memory_allocated() / 1024**2))\n",
    "train_model(model, dataset, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003077ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T12:14:41.605453Z",
     "iopub.status.busy": "2025-06-09T12:14:41.604701Z",
     "iopub.status.idle": "2025-06-09T12:14:41.614760Z",
     "shell.execute_reply": "2025-06-09T12:14:41.614054Z",
     "shell.execute_reply.started": "2025-06-09T12:14:41.605430Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from monai.metrics import DiceMetric, HausdorffDistanceMetric, SurfaceDistanceMetric\n",
    "from monai.transforms import AsDiscrete\n",
    "import torch\n",
    "\n",
    "def test_detector(dataset, model_class, model_path, grayscale=False, scharr=True, scale_factor=1, device=\"cuda\"):\n",
    "    model = model_class().to(device)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()\n",
    "\n",
    "    # MONAI metric utilities\n",
    "    dice_metric = DiceMetric(include_background=False, reduction=\"mean\")\n",
    "    hausdorff = HausdorffDistanceMetric(include_background=False, percentile=95)\n",
    "    surface_dice = SurfaceDistanceMetric(include_background=False, symmetric=True)\n",
    "\n",
    "    post_pred = AsDiscrete(threshold=0.5)\n",
    "    post_label = AsDiscrete(threshold=0.5)\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    print(\"🧪 Running detection on test dataset...\")\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(dataset.test)):\n",
    "            sample = dataset.get_test_index(i, grayscale=grayscale, scharr=scharr)\n",
    "            if sample[0] is None:\n",
    "                continue\n",
    "\n",
    "            image, bin_mask, multi_mask = sample\n",
    "\n",
    "            orig_size = image.shape[-2:]  # Save original size\n",
    "\n",
    "            if scale_factor != 1:\n",
    "                image = F.interpolate(image.unsqueeze(0), scale_factor=1/scale_factor, mode='bilinear', align_corners=False)\n",
    "            else:\n",
    "                image = image.unsqueeze(0)\n",
    "            bin_mask = bin_mask.unsqueeze(0).to(device)\n",
    "            image = image.to(device)\n",
    "            \n",
    "            pred = model(image)\n",
    "\n",
    "            if scale_factor != 1:\n",
    "                pred = F.interpolate(pred, size=orig_size, mode='bilinear', align_corners=False)\n",
    "            \n",
    "            pred_bin = post_pred(torch.sigmoid(pred))\n",
    "            label_bin = post_label(bin_mask)\n",
    "\n",
    "            all_preds.append(pred_bin)\n",
    "            all_labels.append(label_bin)\n",
    "\n",
    "            del image, bin_mask, pred\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    preds_tensor = torch.cat(all_preds, dim=0)\n",
    "    labels_tensor = torch.cat(all_labels, dim=0)\n",
    "\n",
    "    # Compute metrics\n",
    "    dice_val = dice_metric(preds_tensor, labels_tensor).mean().item()\n",
    "    hausdorff_val = hausdorff(preds_tensor, labels_tensor).mean().item()\n",
    "    surface_dice_val = surface_dice(preds_tensor, labels_tensor).mean().item()\n",
    "\n",
    "    print(f\"\\n📊 Metrics:\")\n",
    "    print(f\"🎯 Dice Score: {dice_val:.4f}\")\n",
    "    print(f\"📏 Hausdorff Distance (95th percentile): {hausdorff_val:.4f}\")\n",
    "    print(f\"🌊 Normalized Surface Dice: {surface_dice_val:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca16340",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T12:16:56.926723Z",
     "iopub.status.busy": "2025-06-09T12:16:56.925869Z",
     "iopub.status.idle": "2025-06-09T12:16:56.937924Z",
     "shell.execute_reply": "2025-06-09T12:16:56.937196Z",
     "shell.execute_reply.started": "2025-06-09T12:16:56.926693Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_test(dataset, model_class, model_path, grayscale=False, scale_factor=1, device=\"cuda\"):\n",
    "    model = model_class().to(device)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()\n",
    "\n",
    "    y_true, y_pred = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(len(dataset.test)):\n",
    "            sample = dataset.get_test_index(i, grayscale=grayscale)\n",
    "\n",
    "            image, bin_mask, multi_mask = sample\n",
    "            orig_size = image.shape[-2:]  # Save original size\n",
    "\n",
    "            if scale_factor != 1:\n",
    "                image = F.interpolate(image.unsqueeze(0), scale_factor=1/scale_factor, mode='bilinear', align_corners=False)\n",
    "            else:\n",
    "                image = image.unsqueeze(0)\n",
    "            image = image.to(device)\n",
    "            pred = model(image)\n",
    "\n",
    "            if scale_factor != 1:\n",
    "                pred = F.interpolate(pred, size=orig_size, mode='bilinear', align_corners=False)\n",
    "\n",
    "            pred_bin = (torch.sigmoid(pred).squeeze() > 0.5).cpu().numpy().astype(np.uint8)\n",
    "            true_bin = bin_mask.squeeze().cpu().numpy().astype(np.uint8)\n",
    "\n",
    "            plt.figure(figsize=(10, 5))\n",
    "\n",
    "            # Predicted mask\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.imshow(pred_bin, cmap='gray')\n",
    "            plt.title('Predicted Binary Mask')\n",
    "            plt.axis('off')\n",
    "            \n",
    "            # Ground truth mask\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.imshow(true_bin, cmap='gray')\n",
    "            plt.title('Ground Truth Binary Mask')\n",
    "            plt.axis('off')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b67d83b",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-05-21T07:05:03.293092Z",
     "iopub.status.busy": "2025-05-21T07:05:03.292545Z",
     "iopub.status.idle": "2025-05-21T07:05:05.897321Z",
     "shell.execute_reply": "2025-05-21T07:05:05.896757Z",
     "shell.execute_reply.started": "2025-05-21T07:05:03.293068Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# === CONFIG ===\n",
    "train_dir = \"/kaggle/input/celldetection/ds1/train\"\n",
    "detector_model_path = \"/kaggle/working/best_model.pth\"\n",
    "epochs = 25\n",
    "\n",
    "# === LOAD DATASET ===\n",
    "dataset = CellDataset(train_dir)\n",
    "\n",
    "\n",
    "show_test(dataset, model_class=UnetArhitecture, model_path=detector_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf0d343",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T12:15:12.840982Z",
     "iopub.status.busy": "2025-06-17T12:15:12.840648Z",
     "iopub.status.idle": "2025-06-17T12:15:12.851831Z",
     "shell.execute_reply": "2025-06-17T12:15:12.850969Z",
     "shell.execute_reply.started": "2025-06-17T12:15:12.840957Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SmallerUnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.e1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, padding=1), nn.BatchNorm2d(32), nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, 3, padding=1), nn.BatchNorm2d(32), nn.ReLU()\n",
    "        )\n",
    "        self.max_pooling_e1 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.e2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 48, 3, padding=1), nn.BatchNorm2d(48), nn.ReLU(),\n",
    "            nn.Conv2d(48, 48, 3, padding=1), nn.BatchNorm2d(48), nn.ReLU()\n",
    "        )\n",
    "        self.max_pooling_e2 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.e3 = nn.Sequential(\n",
    "            nn.Conv2d(48, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU()\n",
    "        )\n",
    "        self.max_pooling_e3 = nn.MaxPool2d(2)\n",
    "\n",
    "        # Bottleneck\n",
    "        self.bottle_neck = nn.Sequential(\n",
    "            nn.Conv2d(64, 96, 3, padding=1), nn.BatchNorm2d(96), nn.ReLU(),\n",
    "            nn.Conv2d(96, 96, 3, padding=1), nn.BatchNorm2d(96), nn.ReLU(),\n",
    "            nn.ConvTranspose2d(96, 64, 2, stride=2)\n",
    "        )\n",
    "\n",
    "        # Decoder\n",
    "        self.d3 = nn.Sequential(\n",
    "            nn.Conv2d(64 + 64, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 48, 2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.d2 = nn.Sequential(\n",
    "            nn.Conv2d(48 + 48, 48, 3, padding=1), nn.BatchNorm2d(48), nn.ReLU(),\n",
    "            nn.Conv2d(48, 48, 3, padding=1), nn.BatchNorm2d(48), nn.ReLU(),\n",
    "            nn.ConvTranspose2d(48, 32, 2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.d1 = nn.Sequential(\n",
    "            nn.Conv2d(32 + 32, 32, 3, padding=1), nn.BatchNorm2d(32), nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, 3, padding=1), nn.BatchNorm2d(32), nn.ReLU(),\n",
    "            nn.Conv2d(32, 1, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        e1 = self.e1(x)\n",
    "        e2 = self.e2(self.max_pooling_e1(e1))\n",
    "        e3 = self.e3(self.max_pooling_e2(e2))\n",
    "        bottle = self.bottle_neck(self.max_pooling_e3(e3))\n",
    "\n",
    "        d3 = self.d3(torch.cat([e3, bottle], dim=1))\n",
    "        d2 = self.d2(torch.cat([e2, d3], dim=1))\n",
    "        d1 = self.d1(torch.cat([e1, d2], dim=1))\n",
    "\n",
    "        return d1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01982935",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-05-21T07:37:27.140438Z",
     "iopub.status.busy": "2025-05-21T07:37:27.139930Z",
     "iopub.status.idle": "2025-05-21T07:54:02.272533Z",
     "shell.execute_reply": "2025-05-21T07:54:02.271806Z",
     "shell.execute_reply.started": "2025-05-21T07:37:27.140416Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print(\"Before Dataset: {:.2f} MB\".format(torch.cuda.memory_allocated() / 1024**2))\n",
    "dataset = CellDataSet(batch_size=2)\n",
    "#print(\"Before Unet: {:.2f} MB\".format(torch.cuda.memory_allocated() / 1024**2))\n",
    "model = SmallerUnet()\n",
    "#print(\"By start Memory Allocated: {:.2f} MB\".format(torch.cuda.memory_allocated() / 1024**2))\n",
    "train_model(model, dataset, num_epochs=40, save_path = \"smaller_unet.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b065895",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-07T15:35:23.209912Z",
     "iopub.status.busy": "2025-06-07T15:35:23.209608Z",
     "iopub.status.idle": "2025-06-07T15:35:23.238701Z",
     "shell.execute_reply": "2025-06-07T15:35:23.237691Z",
     "shell.execute_reply.started": "2025-06-07T15:35:23.209861Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_detector(dataset, model_path):\n",
    "    device=\"cuda\"\n",
    "    model = SmallerUnet().to(device)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "\n",
    "    y_true, y_pred = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(dataset)):\n",
    "            image, bin_mask, _ = dataset[i]\n",
    "            image = image.unsqueeze(0).to(device)\n",
    "            pred = model(image)\n",
    "\n",
    "            pred_bin = (torch.sigmoid(pred).squeeze() > 0.5).cpu().numpy().astype(np.uint8)\n",
    "            true_bin = bin_mask.squeeze().cpu().numpy().astype(np.uint8)\n",
    "\n",
    "            y_true.extend(true_bin.flatten())\n",
    "            y_pred.extend(pred_bin.flatten())\n",
    "\n",
    "            del image, bin_mask, pred\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    print(\"\\n📊 Detection Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=[\"Background\", \"Cell\"], zero_division=0))\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Greens',\n",
    "                xticklabels=[\"Pred 0\", \"Pred 1\"], yticklabels=[\"True 0\", \"True 1\"])\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.title(\"Confusion Matrix - Cell Detection\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "train_dir = \"/kaggle/input/celldetection/ds1/train\"\n",
    "detector_model_path = \"/kaggle/working/smaller_unet.pth\"\n",
    "#epochs = 25\n",
    "\n",
    "# === LOAD DATASET ===\n",
    "dataset = CellDataset(train_dir)\n",
    "\n",
    "\n",
    "test_detector(dataset, detector_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0638a5e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T12:20:10.533716Z",
     "iopub.status.busy": "2025-06-17T12:20:10.533410Z",
     "iopub.status.idle": "2025-06-17T12:20:10.545500Z",
     "shell.execute_reply": "2025-06-17T12:20:10.544945Z",
     "shell.execute_reply.started": "2025-06-17T12:20:10.533694Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GrayScaleSmallerUnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.e1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, padding=1), nn.BatchNorm2d(32), nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, 3, padding=1), nn.BatchNorm2d(32), nn.ReLU()\n",
    "        )\n",
    "        self.max_pooling_e1 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.e2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 48, 3, padding=1), nn.BatchNorm2d(48), nn.ReLU(),\n",
    "            nn.Conv2d(48, 48, 3, padding=1), nn.BatchNorm2d(48), nn.ReLU()\n",
    "        )\n",
    "        self.max_pooling_e2 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.e3 = nn.Sequential(\n",
    "            nn.Conv2d(48, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU()\n",
    "        )\n",
    "        self.max_pooling_e3 = nn.MaxPool2d(2)\n",
    "\n",
    "        # Bottleneck\n",
    "        self.bottle_neck = nn.Sequential(\n",
    "            nn.Conv2d(64, 96, 3, padding=1), nn.BatchNorm2d(96), nn.ReLU(),\n",
    "            nn.Conv2d(96, 96, 3, padding=1), nn.BatchNorm2d(96), nn.ReLU(),\n",
    "            nn.ConvTranspose2d(96, 64, 2, stride=2)\n",
    "        )\n",
    "\n",
    "        # Decoder\n",
    "        self.d3 = nn.Sequential(\n",
    "            nn.Conv2d(64 + 64, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 48, 2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.d2 = nn.Sequential(\n",
    "            nn.Conv2d(48 + 48, 48, 3, padding=1), nn.BatchNorm2d(48), nn.ReLU(),\n",
    "            nn.Conv2d(48, 48, 3, padding=1), nn.BatchNorm2d(48), nn.ReLU(),\n",
    "            nn.ConvTranspose2d(48, 32, 2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.d1 = nn.Sequential(\n",
    "            nn.Conv2d(32 + 32, 32, 3, padding=1), nn.BatchNorm2d(32), nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, 3, padding=1), nn.BatchNorm2d(32), nn.ReLU(),\n",
    "            nn.Conv2d(32, 1, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        e1 = self.e1(x)\n",
    "        e2 = self.e2(self.max_pooling_e1(e1))\n",
    "        e3 = self.e3(self.max_pooling_e2(e2))\n",
    "        bottle = self.bottle_neck(self.max_pooling_e3(e3))\n",
    "\n",
    "        d3 = self.d3(torch.cat([e3, bottle], dim=1))\n",
    "        d2 = self.d2(torch.cat([e2, d3], dim=1))\n",
    "        d1 = self.d1(torch.cat([e1, d2], dim=1))\n",
    "\n",
    "        return d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9218a158",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-05-21T09:19:23.226233Z",
     "iopub.status.busy": "2025-05-21T09:19:23.225585Z",
     "iopub.status.idle": "2025-05-21T09:36:33.272320Z",
     "shell.execute_reply": "2025-05-21T09:36:33.271381Z",
     "shell.execute_reply.started": "2025-05-21T09:19:23.226203Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = CellDataSet()\n",
    "model = GrayScaleSmallerUnet()\n",
    "train_model(model, dataset, num_epochs=40, grayscale=True, save_path = \"smaller_unet.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfb76e8",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-05-21T09:42:33.007519Z",
     "iopub.status.busy": "2025-05-21T09:42:33.007245Z",
     "iopub.status.idle": "2025-05-21T09:48:55.363016Z",
     "shell.execute_reply": "2025-05-21T09:48:55.362425Z",
     "shell.execute_reply.started": "2025-05-21T09:42:33.007500Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_detector(dataset, model_class=GrayScaleSmallerUnet, model_path=\"smaller_unet.pth\", grayscale=True)\n",
    "show_test(dataset, model_class=GrayScaleSmallerUnet, model_path=\"smaller_unet.pth\", grayscale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518cf6d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T12:15:44.813823Z",
     "iopub.status.busy": "2025-06-17T12:15:44.813075Z",
     "iopub.status.idle": "2025-06-17T12:18:51.950564Z",
     "shell.execute_reply": "2025-06-17T12:18:51.949628Z",
     "shell.execute_reply.started": "2025-06-17T12:15:44.813795Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = CellDataSet()\n",
    "test_detector(dataset, model_class=UnetArhitecture, model_path=\"best_model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dac7f55",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-17T12:20:19.665749Z",
     "iopub.status.busy": "2025-06-17T12:20:19.665198Z",
     "iopub.status.idle": "2025-06-17T12:20:58.868472Z",
     "shell.execute_reply": "2025-06-17T12:20:58.867491Z",
     "shell.execute_reply.started": "2025-06-17T12:20:19.665724Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_detector(dataset, model_class=GrayScaleSmallerUnet, model_path=\"smaller_unet.pth\", grayscale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6aa54d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T11:49:18.444208Z",
     "iopub.status.busy": "2025-06-17T11:49:18.443159Z",
     "iopub.status.idle": "2025-06-17T11:49:18.455499Z",
     "shell.execute_reply": "2025-06-17T11:49:18.454643Z",
     "shell.execute_reply.started": "2025-06-17T11:49:18.444180Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GrayScaleMediumUnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.e1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, padding=1), nn.BatchNorm2d(32), nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, 3, padding=1), nn.BatchNorm2d(32), nn.ReLU()\n",
    "        )\n",
    "        self.max_pooling_e1 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.e2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU()\n",
    "        )\n",
    "        self.max_pooling_e2 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.e3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU()\n",
    "        )\n",
    "        self.max_pooling_e3 = nn.MaxPool2d(2)\n",
    "\n",
    "        # Bottleneck\n",
    "        self.bottle_neck = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, 3, padding=1), nn.BatchNorm2d(256), nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, 3, padding=1), nn.BatchNorm2d(256), nn.ReLU(),\n",
    "            nn.ConvTranspose2d(256, 128, 2, stride=2)\n",
    "        )\n",
    "\n",
    "        # Decoder\n",
    "        self.d3 = nn.Sequential(\n",
    "            nn.Conv2d(128 + 128, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.d2 = nn.Sequential(\n",
    "            nn.Conv2d(64 + 64, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, 2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.d1 = nn.Sequential(\n",
    "            nn.Conv2d(32 + 32, 32, 3, padding=1), nn.BatchNorm2d(32), nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, 3, padding=1), nn.BatchNorm2d(32), nn.ReLU(),\n",
    "            nn.Conv2d(32, 1, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        e1 = self.e1(x)\n",
    "        e2 = self.e2(self.max_pooling_e1(e1))\n",
    "        e3 = self.e3(self.max_pooling_e2(e2))\n",
    "        bottle = self.bottle_neck(self.max_pooling_e3(e3))\n",
    "\n",
    "        d3 = self.d3(torch.cat([e3, bottle], dim=1))\n",
    "        d2 = self.d2(torch.cat([e2, d3], dim=1))\n",
    "        d1 = self.d1(torch.cat([e1, d2], dim=1))\n",
    "\n",
    "        return d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc0ba55",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-05-22T15:21:56.271475Z",
     "iopub.status.busy": "2025-05-22T15:21:56.271214Z",
     "iopub.status.idle": "2025-05-22T16:08:42.427766Z",
     "shell.execute_reply": "2025-05-22T16:08:42.426644Z",
     "shell.execute_reply.started": "2025-05-22T15:21:56.271458Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = CellDataSet()\n",
    "model = GrayScaleMediumUnet()\n",
    "train_model(model, dataset, num_epochs=80, grayscale=True, save_path = \"dice_medium.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c912791c",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-05-22T16:12:54.180448Z",
     "iopub.status.busy": "2025-05-22T16:12:54.179958Z",
     "iopub.status.idle": "2025-05-22T16:13:32.515777Z",
     "shell.execute_reply": "2025-05-22T16:13:32.515136Z",
     "shell.execute_reply.started": "2025-05-22T16:12:54.180424Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_detector(dataset, model_class=GrayScaleMediumUnet, model_path=\"dice_medium.pth\", grayscale=True)\n",
    "show_test(dataset, model_class=GrayScaleMediumUnet, model_path=\"dice_medium.pth\", grayscale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0570275",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-05-22T16:14:24.176358Z",
     "iopub.status.busy": "2025-05-22T16:14:24.175778Z",
     "iopub.status.idle": "2025-05-22T17:21:00.624475Z",
     "shell.execute_reply": "2025-05-22T17:21:00.623803Z",
     "shell.execute_reply.started": "2025-05-22T16:14:24.176335Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = CellDataSet()\n",
    "model = UnetArhitecture()\n",
    "train_model(model, dataset, num_epochs=80, save_path = \"dice_unet.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26728516",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-05-22T19:53:21.034336Z",
     "iopub.status.busy": "2025-05-22T19:53:21.033819Z",
     "iopub.status.idle": "2025-05-22T19:54:17.637079Z",
     "shell.execute_reply": "2025-05-22T19:54:17.636515Z",
     "shell.execute_reply.started": "2025-05-22T19:53:21.034317Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = CellDataSet()\n",
    "test_detector(dataset, model_class=UnetArhitecture, model_path=\"dice_unet.pth\")\n",
    "show_test(dataset, model_class=UnetArhitecture, model_path=\"dice_unet.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6f8070",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-05-23T09:51:25.200482Z",
     "iopub.status.busy": "2025-05-23T09:51:25.200178Z",
     "iopub.status.idle": "2025-05-23T11:02:31.209196Z",
     "shell.execute_reply": "2025-05-23T11:02:31.207767Z",
     "shell.execute_reply.started": "2025-05-23T09:51:25.200461Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = CellDataSet()\n",
    "model = GrayScaleMediumUnet()\n",
    "train_model(model, dataset, num_epochs=80, grayscale=True, save_path = \"dice_HDmedium.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539d7db1",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-05-23T11:09:48.500147Z",
     "iopub.status.busy": "2025-05-23T11:09:48.499858Z",
     "iopub.status.idle": "2025-05-23T11:10:36.067504Z",
     "shell.execute_reply": "2025-05-23T11:10:36.066670Z",
     "shell.execute_reply.started": "2025-05-23T11:09:48.500128Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = CellDataSet()\n",
    "test_detector(dataset, model_class=GrayScaleMediumUnet, model_path=\"dice_HDmedium.pth\",grayscale=True)\n",
    "show_test(dataset, model_class=GrayScaleMediumUnet, model_path=\"dice_HDmedium.pth\",grayscale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9aa4ecd",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-05-23T11:12:16.949717Z",
     "iopub.status.busy": "2025-05-23T11:12:16.948995Z",
     "iopub.status.idle": "2025-05-23T11:45:38.699154Z",
     "shell.execute_reply": "2025-05-23T11:45:38.698127Z",
     "shell.execute_reply.started": "2025-05-23T11:12:16.949688Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = GrayScaleMediumUnet()\n",
    "model.load_state_dict(torch.load(\"dice_HDmedium.pth\"))  # Load weights\n",
    "\n",
    "train_model(model, dataset, num_epochs=40, grayscale=True, save_path=\"dice_HDmedium2.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a218ccbf",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-05-23T11:55:45.759573Z",
     "iopub.status.busy": "2025-05-23T11:55:45.758960Z",
     "iopub.status.idle": "2025-05-23T11:56:33.914065Z",
     "shell.execute_reply": "2025-05-23T11:56:33.913209Z",
     "shell.execute_reply.started": "2025-05-23T11:55:45.759550Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = CellDataSet()\n",
    "test_detector(dataset, model_class=GrayScaleMediumUnet, model_path=\"dice_HDmedium.pth\",grayscale=True)\n",
    "show_test(dataset, model_class=GrayScaleMediumUnet, model_path=\"dice_HDmedium.pth\",grayscale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48472a0f",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-05-27T07:47:11.827144Z",
     "iopub.status.busy": "2025-05-27T07:47:11.826868Z",
     "iopub.status.idle": "2025-05-27T09:34:10.127850Z",
     "shell.execute_reply": "2025-05-27T09:34:10.126836Z",
     "shell.execute_reply.started": "2025-05-27T07:47:11.827124Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = CellDataSet()\n",
    "model = GrayScaleMediumUnet()\n",
    "#0,3 cross 0.6 dice 0,001 haus\n",
    "train_model(model, dataset, num_epochs=80, grayscale=True, save_path = \"dice_MultiLossMedium.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12d0a7c",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-05-27T09:40:23.718283Z",
     "iopub.status.busy": "2025-05-27T09:40:23.718013Z",
     "iopub.status.idle": "2025-05-27T09:41:12.696451Z",
     "shell.execute_reply": "2025-05-27T09:41:12.695910Z",
     "shell.execute_reply.started": "2025-05-27T09:40:23.718264Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = CellDataSet()\n",
    "test_detector(dataset, model_class=GrayScaleMediumUnet, model_path=\"dice_MultiLossMedium.pth\",grayscale=True)\n",
    "show_test(dataset, model_class=GrayScaleMediumUnet, model_path=\"dice_MultiLossMedium.pth\",grayscale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad82282",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-05-27T09:43:43.225857Z",
     "iopub.status.busy": "2025-05-27T09:43:43.225484Z",
     "iopub.status.idle": "2025-05-27T10:43:13.838448Z",
     "shell.execute_reply": "2025-05-27T10:43:13.837664Z",
     "shell.execute_reply.started": "2025-05-27T09:43:43.225837Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = GrayScaleMediumUnet()\n",
    "model.load_state_dict(torch.load(\"dice_MultiLossMedium.pth\"))  # Load weights\n",
    "\n",
    "train_model(model, dataset, num_epochs=80, grayscale=True, save_path=\"dice_MultiLossMedium.pth\")\n",
    "test_detector(dataset, model_class=GrayScaleMediumUnet, model_path=\"dice_MultiLossMedium.pth\",grayscale=True)\n",
    "show_test(dataset, model_class=GrayScaleMediumUnet, model_path=\"dice_MultiLossMedium.pth\",grayscale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0c49bd",
   "metadata": {
    "collapsed": true,
    "execution": {
     "execution_failed": "2025-05-27T11:27:26.050Z",
     "iopub.execute_input": "2025-05-27T10:52:27.582374Z",
     "iopub.status.busy": "2025-05-27T10:52:27.582121Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = CellDataSet()\n",
    "model = GrayScaleMediumUnet()\n",
    "#0,7 cross 0.3 dice\n",
    "train_model(model, dataset, num_epochs=80, grayscale=True, save_path = \"GrayCr07Dice03Medium.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6c7cc4",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-05-27T13:44:57.264189Z",
     "iopub.status.busy": "2025-05-27T13:44:57.263442Z",
     "iopub.status.idle": "2025-05-27T13:45:47.684555Z",
     "shell.execute_reply": "2025-05-27T13:45:47.683950Z",
     "shell.execute_reply.started": "2025-05-27T13:44:57.264163Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = CellDataSet()\n",
    "test_detector(dataset, model_class=GrayScaleMediumUnet, model_path=\"GrayCr07Dice03Medium.pth\",grayscale=True)\n",
    "show_test(dataset, model_class=GrayScaleMediumUnet, model_path=\"GrayCr07Dice03Medium.pth\",grayscale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc76557",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-05-27T13:52:28.478909Z",
     "iopub.status.busy": "2025-05-27T13:52:28.478316Z",
     "iopub.status.idle": "2025-05-27T13:53:03.747392Z",
     "shell.execute_reply": "2025-05-27T13:53:03.746412Z",
     "shell.execute_reply.started": "2025-05-27T13:52:28.478886Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_detector(dataset, model_class=GrayScaleSmallerUnet, model_path=\"smaller_unet.pth\",grayscale=True)\n",
    "show_test(dataset, model_class=GrayScaleSmallerUnet, model_path=\"smaller_unet.pth\",grayscale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bc6cb5",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-05-27T13:54:00.876130Z",
     "iopub.status.busy": "2025-05-27T13:54:00.875858Z",
     "iopub.status.idle": "2025-05-27T14:21:52.185129Z",
     "shell.execute_reply": "2025-05-27T14:21:52.184361Z",
     "shell.execute_reply.started": "2025-05-27T13:54:00.876111Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = GrayScaleSmallerUnet()\n",
    "#0,7 cross 0.3 dice\n",
    "train_model(model, dataset, num_epochs=80, grayscale=True, save_path = \"GrayCr07Dice03Small.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71567e3",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-05-27T14:25:50.485003Z",
     "iopub.status.busy": "2025-05-27T14:25:50.484246Z",
     "iopub.status.idle": "2025-05-27T14:26:28.375895Z",
     "shell.execute_reply": "2025-05-27T14:26:28.375265Z",
     "shell.execute_reply.started": "2025-05-27T14:25:50.484980Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_detector(dataset, model_class=GrayScaleSmallerUnet, model_path=\"GrayCr07Dice03Small.pth\",grayscale=True)\n",
    "show_test(dataset, model_class=GrayScaleSmallerUnet, model_path=\"GrayCr07Dice03Small.pth\",grayscale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab368a7e",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-05-27T14:38:32.043941Z",
     "iopub.status.busy": "2025-05-27T14:38:32.043652Z",
     "iopub.status.idle": "2025-05-27T15:57:58.283619Z",
     "shell.execute_reply": "2025-05-27T15:57:58.282563Z",
     "shell.execute_reply.started": "2025-05-27T14:38:32.043919Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = GrayScaleSmallerUnet()\n",
    "dataset = CellDataSet()\n",
    "train_model(model, dataset, num_epochs=80, grayscale=True, save_path = \"GrayCr03Dice06H0001Small.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989e421f",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-05-27T16:17:56.718717Z",
     "iopub.status.busy": "2025-05-27T16:17:56.718123Z",
     "iopub.status.idle": "2025-05-27T16:18:43.596957Z",
     "shell.execute_reply": "2025-05-27T16:18:43.596321Z",
     "shell.execute_reply.started": "2025-05-27T16:17:56.718693Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = CellDataSet()\n",
    "test_detector(dataset, model_class=GrayScaleSmallerUnet, model_path=\"GrayCr03Dice06H0001Small.pth\",grayscale=True)\n",
    "show_test(dataset, model_class=GrayScaleSmallerUnet, model_path=\"GrayCr03Dice06H0001Small.pth\",grayscale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aced47d5",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-05-27T16:22:29.250094Z",
     "iopub.status.busy": "2025-05-27T16:22:29.249781Z",
     "iopub.status.idle": "2025-05-27T17:44:38.468663Z",
     "shell.execute_reply": "2025-05-27T17:44:38.467420Z",
     "shell.execute_reply.started": "2025-05-27T16:22:29.250074Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = SmallerUnet()\n",
    "#0,7 cross 0.3 dice\n",
    "train_model(model, dataset, num_epochs=80, save_path = \"Cr07Dice03Small.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c065fa0",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-05-29T05:32:18.128938Z",
     "iopub.status.busy": "2025-05-29T05:32:18.128389Z",
     "iopub.status.idle": "2025-05-29T05:33:17.112817Z",
     "shell.execute_reply": "2025-05-29T05:33:17.112023Z",
     "shell.execute_reply.started": "2025-05-29T05:32:18.128912Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = CellDataSet()\n",
    "test_detector(dataset, model_class=SmallerUnet, model_path=\"Cr07Dice03Small.pth\")\n",
    "show_test(dataset, model_class=SmallerUnet, model_path=\"Cr07Dice03Small.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620ba9fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T11:08:05.825942Z",
     "iopub.status.busy": "2025-06-17T11:08:05.825579Z",
     "iopub.status.idle": "2025-06-17T11:08:05.837927Z",
     "shell.execute_reply": "2025-06-17T11:08:05.837043Z",
     "shell.execute_reply.started": "2025-06-17T11:08:05.825914Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Layer4GrayScaleSmallerUnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.e1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, padding=1), nn.BatchNorm2d(32), nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, 3, padding=1), nn.BatchNorm2d(32), nn.ReLU()\n",
    "        )\n",
    "        self.max_pooling_e1 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.e2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 48, 3, padding=1), nn.BatchNorm2d(48), nn.ReLU(),\n",
    "            nn.Conv2d(48, 48, 3, padding=1), nn.BatchNorm2d(48), nn.ReLU()\n",
    "        )\n",
    "        self.max_pooling_e2 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.e3 = nn.Sequential(\n",
    "            nn.Conv2d(48, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU()\n",
    "        )\n",
    "        self.max_pooling_e3 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.e4 = nn.Sequential(\n",
    "            nn.Conv2d(64, 80, 3, padding=1), nn.BatchNorm2d(80), nn.ReLU(),\n",
    "            nn.Conv2d(80, 80, 3, padding=1), nn.BatchNorm2d(80), nn.ReLU()\n",
    "        )\n",
    "        self.max_pooling_e4 = nn.MaxPool2d(2)\n",
    "\n",
    "        # Bottleneck\n",
    "        self.bottle_neck = nn.Sequential(\n",
    "            nn.Conv2d(80, 96, 3, padding=1), nn.BatchNorm2d(96), nn.ReLU(),\n",
    "            nn.Conv2d(96, 96, 3, padding=1), nn.BatchNorm2d(96), nn.ReLU(),\n",
    "            nn.ConvTranspose2d(96, 80, 2, stride=2)\n",
    "        )\n",
    "\n",
    "        # Decoder\n",
    "        self.d4 = nn.Sequential(\n",
    "            nn.Conv2d(80 + 80, 80, 3, padding=1), nn.BatchNorm2d(80), nn.ReLU(),\n",
    "            nn.Conv2d(80, 80, 3, padding=1), nn.BatchNorm2d(80), nn.ReLU(),\n",
    "            nn.ConvTranspose2d(80, 64, 2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.d3 = nn.Sequential(\n",
    "            nn.Conv2d(64 + 64, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 48, 2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.d2 = nn.Sequential(\n",
    "            nn.Conv2d(48 + 48, 48, 3, padding=1), nn.BatchNorm2d(48), nn.ReLU(),\n",
    "            nn.Conv2d(48, 48, 3, padding=1), nn.BatchNorm2d(48), nn.ReLU(),\n",
    "            nn.ConvTranspose2d(48, 32, 2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.d1 = nn.Sequential(\n",
    "            nn.Conv2d(32 + 32, 32, 3, padding=1), nn.BatchNorm2d(32), nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, 3, padding=1), nn.BatchNorm2d(32), nn.ReLU(),\n",
    "            nn.Conv2d(32, 1, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        e1 = self.e1(x)\n",
    "        e2 = self.e2(self.max_pooling_e1(e1))\n",
    "        e3 = self.e3(self.max_pooling_e2(e2))\n",
    "        e4 = self.e4(self.max_pooling_e3(e3))\n",
    "        bottle = self.bottle_neck(self.max_pooling_e4(e4))\n",
    "\n",
    "        d4 = self.d4(torch.cat([e4, bottle], dim=1))\n",
    "        d3 = self.d3(torch.cat([e3, d4], dim=1))\n",
    "        d2 = self.d2(torch.cat([e2, d3], dim=1))\n",
    "        d1 = self.d1(torch.cat([e1, d2], dim=1))\n",
    "\n",
    "        return d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf519b4",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-05-29T05:50:26.877094Z",
     "iopub.status.busy": "2025-05-29T05:50:26.876384Z",
     "iopub.status.idle": "2025-05-29T06:45:47.533357Z",
     "shell.execute_reply": "2025-05-29T06:45:47.532350Z",
     "shell.execute_reply.started": "2025-05-29T05:50:26.877069Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Layer4GrayScaleSmallerUnet()\n",
    "dataset = CellDataSet()\n",
    "#0,7 cross 0.3 dice\n",
    "train_model(model, dataset, num_epochs=80, save_path = \"Cr07Dice03L4Small.pth\",grayscale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a376469",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-05-29T09:20:27.777697Z",
     "iopub.status.busy": "2025-05-29T09:20:27.777098Z",
     "iopub.status.idle": "2025-05-29T10:31:11.655409Z",
     "shell.execute_reply": "2025-05-29T10:31:11.654312Z",
     "shell.execute_reply.started": "2025-05-29T09:20:27.777674Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = CellDataSet()\n",
    "model = Layer4GrayScaleSmallerUnet()\n",
    "model.load_state_dict(torch.load(\"Cr07Dice03L4Small.pth\"))  # Load weights\n",
    "\n",
    "train_model(model, dataset, num_epochs=80, grayscale=True, save_path=\"Cr07Dice03L4Small.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454c122e",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-05-29T10:50:22.885073Z",
     "iopub.status.busy": "2025-05-29T10:50:22.884618Z",
     "iopub.status.idle": "2025-05-29T10:51:08.344288Z",
     "shell.execute_reply": "2025-05-29T10:51:08.343677Z",
     "shell.execute_reply.started": "2025-05-29T10:50:22.885050Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = CellDataSet()\n",
    "test_detector(dataset, model_class=Layer4GrayScaleSmallerUnet, model_path=\"Cr07Dice03L4Small.pth\", grayscale=True)\n",
    "show_test(dataset, model_class=Layer4GrayScaleSmallerUnet, model_path=\"Cr07Dice03L4Small.pth\", grayscale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd8ada7",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-05-29T14:13:13.458713Z",
     "iopub.status.busy": "2025-05-29T14:13:13.458072Z",
     "iopub.status.idle": "2025-05-29T15:21:50.114591Z",
     "shell.execute_reply": "2025-05-29T15:21:50.113702Z",
     "shell.execute_reply.started": "2025-05-29T14:13:13.458690Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = CellDataSet()\n",
    "model = Layer4GrayScaleSmallerUnet()\n",
    "model.load_state_dict(torch.load(\"Cr07Dice03L4Small2.pth\")) \n",
    "\n",
    "train_model(model, dataset, num_epochs=80, grayscale=True, save_path=\"Cr07Dice03L4Small2.pth\")\n",
    "test_detector(dataset, model_class=Layer4GrayScaleSmallerUnet, model_path=\"Cr07Dice03L4Small2.pth\", grayscale=True)\n",
    "show_test(dataset, model_class=Layer4GrayScaleSmallerUnet, model_path=\"Cr07Dice03L4Small2.pth\", grayscale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ef4b7d",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-05-29T17:20:08.212432Z",
     "iopub.status.busy": "2025-05-29T17:20:08.211694Z",
     "iopub.status.idle": "2025-05-29T18:00:44.210624Z",
     "shell.execute_reply": "2025-05-29T18:00:44.209058Z",
     "shell.execute_reply.started": "2025-05-29T17:20:08.212409Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = CellDataSet()\n",
    "model = Layer4GrayScaleSmallerUnet()\n",
    "model.load_state_dict(torch.load(\"CDH05_0005.pth\"))\n",
    "test_detector(dataset, model_class=Layer4GrayScaleSmallerUnet, model_path=\"CDH05_0005.pth\", grayscale=True)\n",
    "show_test(dataset, model_class=Layer4GrayScaleSmallerUnet, model_path=\"CDH05_0005.pth\", grayscale=True)\n",
    "train_model(model, dataset, num_epochs=80, grayscale=True, save_path=\"CDH05_0005.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b379c8",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-07T15:39:22.146786Z",
     "iopub.status.busy": "2025-06-07T15:39:22.146520Z",
     "iopub.status.idle": "2025-06-07T17:44:18.014809Z",
     "shell.execute_reply": "2025-06-07T17:44:18.014137Z",
     "shell.execute_reply.started": "2025-06-07T15:39:22.146769Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = CellDataSet()\n",
    "model = GrayScaleSmallerUnet()\n",
    "\n",
    "train_model(model, dataset, num_epochs=80, grayscale=True, save_path=\"F05Dice05H0002L4Small2.pth\")\n",
    "test_detector(dataset, model_class=GrayScaleSmallerUnet, model_path=\"F05Dice05H0002L4Small2.pth\", grayscale=True)\n",
    "show_test(dataset, model_class=GrayScaleSmallerUnet, model_path=\"F05Dice05H0002L4Small2.pth\", grayscale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f578e1",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-07T17:53:25.735507Z",
     "iopub.status.busy": "2025-06-07T17:53:25.735208Z",
     "iopub.status.idle": "2025-06-07T19:02:20.876357Z",
     "shell.execute_reply": "2025-06-07T19:02:20.874539Z",
     "shell.execute_reply.started": "2025-06-07T17:53:25.735485Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = CellDataSet()\n",
    "model = GrayScaleSmallerUnet()\n",
    "\n",
    "train_model(model, dataset, num_epochs=80, grayscale=True, save_path=\"F07Dice03H0002L4Small2.pth\")\n",
    "test_detector(dataset, model_class=GrayScaleSmallerUnet, model_path=\"F07Dice03H0002L4Small2.pth\", grayscale=True)\n",
    "show_test(dataset, model_class=GrayScaleSmallerUnet, model_path=\"F07Dice03H0002L4Small2.pth\", grayscale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111d34e2",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-08T05:48:31.437004Z",
     "iopub.status.busy": "2025-06-08T05:48:31.436722Z",
     "iopub.status.idle": "2025-06-08T06:18:44.029598Z",
     "shell.execute_reply": "2025-06-08T06:18:44.028978Z",
     "shell.execute_reply.started": "2025-06-08T05:48:31.436984Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = CellDataSet()\n",
    "model = GrayScaleSmallerUnet()\n",
    "model.load_state_dict(torch.load(\"F07Dice03H0002L4Small2.pth\"))\n",
    "test_detector(dataset, model_class=GrayScaleSmallerUnet, model_path=\"F07Dice03H0002L4Small2.pth\", grayscale=True)\n",
    "show_test(dataset, model_class=GrayScaleSmallerUnet, model_path=\"F07Dice03H0002L4Small2.pth\", grayscale=True)\n",
    "train_model(model, dataset, num_epochs=80, grayscale=True, save_path=\"F07Dice03H0002L4Small2.pth\")\n",
    "test_detector(dataset, model_class=GrayScaleSmallerUnet, model_path=\"F07Dice03H0002L4Small2.pth\", grayscale=True)\n",
    "show_test(dataset, model_class=GrayScaleSmallerUnet, model_path=\"F07Dice03H0002L4Small2.pth\", grayscale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7d19e6",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-08T18:59:13.265824Z",
     "iopub.status.busy": "2025-06-08T18:59:13.265210Z",
     "iopub.status.idle": "2025-06-08T19:29:27.497431Z",
     "shell.execute_reply": "2025-06-08T19:29:27.496802Z",
     "shell.execute_reply.started": "2025-06-08T18:59:13.265800Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = CellDataSet()\n",
    "model = GrayScaleSmallerUnet()\n",
    "\n",
    "train_model(model, dataset, num_epochs=80, grayscale=True, save_path=\"F05Dice05BC052.pth\")\n",
    "test_detector(dataset, model_class=GrayScaleSmallerUnet, model_path=\"F05Dice05BC052.pth\", grayscale=True)\n",
    "show_test(dataset, model_class=GrayScaleSmallerUnet, model_path=\"F05Dice05BC052.pth\", grayscale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e93180e",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-09T11:49:13.008947Z",
     "iopub.status.busy": "2025-06-09T11:49:13.008462Z",
     "iopub.status.idle": "2025-06-09T12:01:27.515466Z",
     "shell.execute_reply": "2025-06-09T12:01:27.514494Z",
     "shell.execute_reply.started": "2025-06-09T11:49:13.008922Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = CellDataSet()\n",
    "model = GrayScaleSmallerUnet()\n",
    "\n",
    "# Antrenare\n",
    "train_model(model, dataset, num_epochs=80, grayscale=True, scale_factor=2, save_path=\"SC2F05Dice05BC052.pth\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8a88a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T12:17:03.887395Z",
     "iopub.status.busy": "2025-06-09T12:17:03.886736Z",
     "iopub.status.idle": "2025-06-09T12:17:35.918934Z",
     "shell.execute_reply": "2025-06-09T12:17:35.918406Z",
     "shell.execute_reply.started": "2025-06-09T12:17:03.887370Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Testare\n",
    "test_detector(dataset, model_class=GrayScaleSmallerUnet, model_path=\"SC2F05Dice05BC052.pth\", grayscale=True, scale_factor=2)\n",
    "show_test(dataset, model_class=GrayScaleSmallerUnet, model_path=\"SC2F05Dice05BC052.pth\", grayscale=True, scale_factor=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a916c06e",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-09T12:23:26.340944Z",
     "iopub.status.busy": "2025-06-09T12:23:26.340643Z",
     "iopub.status.idle": "2025-06-09T12:33:14.935530Z",
     "shell.execute_reply": "2025-06-09T12:33:14.934925Z",
     "shell.execute_reply.started": "2025-06-09T12:23:26.340923Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = CellDataSet()\n",
    "model = GrayScaleSmallerUnet()\n",
    "\n",
    "train_model(model, dataset, num_epochs=80, grayscale=True, save_path=\"F07Dice015BC015.pth\")\n",
    "test_detector(dataset, model_class=GrayScaleSmallerUnet, model_path=\"F07Dice015BC015.pth\", grayscale=True)\n",
    "show_test(dataset, model_class=GrayScaleSmallerUnet, model_path=\"F07Dice015BC015.pth\", grayscale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a56ecc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T11:52:57.856020Z",
     "iopub.status.busy": "2025-06-17T11:52:57.855728Z",
     "iopub.status.idle": "2025-06-17T11:52:57.867668Z",
     "shell.execute_reply": "2025-06-17T11:52:57.866819Z",
     "shell.execute_reply.started": "2025-06-17T11:52:57.855998Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GrUnetArhitecture(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        #Encoder\n",
    "        self.e1 = nn.Sequential(\n",
    "            nn.Conv2d(1,64,3,padding=1),nn.BatchNorm2d(64),nn.ReLU(),\n",
    "            nn.Conv2d(64,64,3,padding=1),nn.BatchNorm2d(64),nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.max_pooling_e1 = nn.MaxPool2d(2) \n",
    "        \n",
    "        self.e2 = nn.Sequential(\n",
    "            nn.Conv2d(64,128,3,padding=1),nn.BatchNorm2d(128),nn.ReLU(),\n",
    "            nn.Conv2d(128,128,3,padding=1),nn.BatchNorm2d(128),nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.max_pooling_e2 = nn.MaxPool2d(2) \n",
    "        \n",
    "        self.e3 = nn.Sequential(\n",
    "            nn.Conv2d(128,256,3,padding=1),nn.BatchNorm2d(256),nn.ReLU(),\n",
    "            nn.Conv2d(256,256,3,padding=1),nn.BatchNorm2d(256),nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        #BottleNeck\n",
    "        self.max_pooling_e3 = nn.MaxPool2d(2)\n",
    "        self.bottle_neck = nn.Sequential(\n",
    "            nn.Conv2d(256,512,3,padding=1),nn.BatchNorm2d(512),nn.ReLU(),\n",
    "            nn.Conv2d(512,512,3,padding=1),nn.BatchNorm2d(512),nn.ReLU(),\n",
    "            nn.ConvTranspose2d(512, 256, 2, stride=2)\n",
    "        )\n",
    "    \n",
    "        self.d3 = nn.Sequential(\n",
    "            nn.Conv2d(512,256,3,padding=1),nn.BatchNorm2d(256),nn.ReLU(), #at this part concat with e3 (256 from e3 + 256 from bottle_neck)\n",
    "            nn.Conv2d(256,256,3,padding=1),nn.BatchNorm2d(256),nn.ReLU(),\n",
    "            nn.ConvTranspose2d(256, 128, 2, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.d2 = nn.Sequential(\n",
    "            nn.Conv2d(256,128,3,padding=1),nn.BatchNorm2d(128),nn.ReLU(), #at this part concat with e2 (128 from e2 + 128 from d3)\n",
    "            nn.Conv2d(128,128,3,padding=1),nn.BatchNorm2d(128),nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.d1 = nn.Sequential(\n",
    "            nn.Conv2d(128,64,3,padding=1),nn.BatchNorm2d(64),nn.ReLU(), #at this part concat with e1 (64 from e1 + 64 from d2)\n",
    "            nn.Conv2d(64,64,3,padding=1),nn.BatchNorm2d(64),nn.ReLU(),\n",
    "            nn.Conv2d(64, 1, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #print(\"Input:\", x.shape)\n",
    "        e1 = self.e1(x)\n",
    "        #print(\"e1:\", e1.shape)\n",
    "        e2 = self.e2(self.max_pooling_e1(e1))\n",
    "        #print(\"e2:\", e2.shape)\n",
    "        e3 = self.e3(self.max_pooling_e2(e2))\n",
    "        #print(\"e3:\", e3.shape)\n",
    "        bottle_neck = self.bottle_neck(self.max_pooling_e3(e3))\n",
    "        #print(\"bottleneck:\", bottle_neck.shape)\n",
    "        d3 = self.d3(torch.cat([e3, bottle_neck], dim=1))\n",
    "        #print(\"d3:\", d3.shape)\n",
    "        d2 = self.d2(torch.cat([e2, d3], dim=1))\n",
    "        #print(\"d2:\", d2.shape)\n",
    "        d1 = self.d1(torch.cat([e1, d2], dim=1))\n",
    "        #print(\"d1 / Output:\", d1.shape)\n",
    "        return d1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2d4444",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-09T12:52:51.144870Z",
     "iopub.status.busy": "2025-06-09T12:52:51.144596Z",
     "iopub.status.idle": "2025-06-09T13:42:15.503524Z",
     "shell.execute_reply": "2025-06-09T13:42:15.502789Z",
     "shell.execute_reply.started": "2025-06-09T12:52:51.144848Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = CellDataSet()\n",
    "model = GrUnetArhitecture()\n",
    "\n",
    "train_model(model, dataset, num_epochs=80, grayscale=True, save_path=\"BUGF07Dice015BC015.pth\")\n",
    "test_detector(dataset, model_class=GrUnetArhitecture, model_path=\"BUGF07Dice015BC015.pth\", grayscale=True)\n",
    "show_test(dataset, model_class=GrUnetArhitecture, model_path=\"BUGF07Dice015BC015.pth\", grayscale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6f827c",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-09T13:51:50.537517Z",
     "iopub.status.busy": "2025-06-09T13:51:50.536800Z",
     "iopub.status.idle": "2025-06-09T15:09:01.798468Z",
     "shell.execute_reply": "2025-06-09T15:09:01.797871Z",
     "shell.execute_reply.started": "2025-06-09T13:51:50.537494Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = CellDataSet()\n",
    "model = GrUnetArhitecture()\n",
    "\n",
    "train_model(model, dataset, num_epochs=80, grayscale=True, save_path=\"BUGF05Dice05BC05.pth\")\n",
    "test_detector(dataset, model_class=GrUnetArhitecture, model_path=\"BUGF05Dice05BC05.pth\", grayscale=True)\n",
    "show_test(dataset, model_class=GrUnetArhitecture, model_path=\"BUGF05Dice05BC05.pth\", grayscale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e46ffb",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-09T15:15:46.098165Z",
     "iopub.status.busy": "2025-06-09T15:15:46.097802Z",
     "iopub.status.idle": "2025-06-09T15:31:32.847846Z",
     "shell.execute_reply": "2025-06-09T15:31:32.847216Z",
     "shell.execute_reply.started": "2025-06-09T15:15:46.098141Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = CellDataSet()\n",
    "model = GrUnetArhitecture()\n",
    "\n",
    "train_model(model, dataset, num_epochs=80, grayscale=True, scale_factor=2,save_path=\"SC2BUGF05Dice05BC05.pth\")\n",
    "test_detector(dataset, model_class=GrUnetArhitecture,scale_factor=2, model_path=\"SC2BUGF05Dice05BC05.pth\", grayscale=True)\n",
    "show_test(dataset, model_class=GrUnetArhitecture,scale_factor=2, model_path=\"SC2BUGF05Dice05BC05.pth\", grayscale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68943490",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-09T15:52:23.213732Z",
     "iopub.status.busy": "2025-06-09T15:52:23.213246Z",
     "iopub.status.idle": "2025-06-09T16:16:44.650095Z",
     "shell.execute_reply": "2025-06-09T16:16:44.649496Z",
     "shell.execute_reply.started": "2025-06-09T15:52:23.213709Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = CellDataSet()\n",
    "model = GrUnetArhitecture()\n",
    "\n",
    "train_model(model, dataset, num_epochs=80, grayscale=True, scale_factor=2,save_path=\"SC2BUGF015Dice07BC015.pth\")\n",
    "test_detector(dataset, model_class=GrUnetArhitecture,scale_factor=2, model_path=\"SC2BUGF015Dice07BC015.pth\", grayscale=True)\n",
    "show_test(dataset, model_class=GrUnetArhitecture,scale_factor=2, model_path=\"SC2BUGF015Dice07BC015.pth\", grayscale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9a56aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T12:15:24.382222Z",
     "iopub.status.busy": "2025-06-17T12:15:24.381618Z",
     "iopub.status.idle": "2025-06-17T12:15:24.414609Z",
     "shell.execute_reply": "2025-06-17T12:15:24.413820Z",
     "shell.execute_reply.started": "2025-06-17T12:15:24.382193Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from monai.metrics import DiceMetric, HausdorffDistanceMetric, SurfaceDistanceMetric\n",
    "from monai.transforms import AsDiscrete\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def test_detector(dataset, model_class, model_path, grayscale=False, scharr=False, scale_factor=1, device=\"cuda\"):\n",
    "    model = model_class().to(device)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()\n",
    "    \n",
    "    # MONAI metric utilities\n",
    "    dice_metric = DiceMetric(include_background=False, reduction=\"none\")  # Changed to \"none\" to get per-image scores\n",
    "    hausdorff = HausdorffDistanceMetric(include_background=False, percentile=95, reduction=\"none\")\n",
    "    surface_dice = SurfaceDistanceMetric(include_background=False, symmetric=True, reduction=\"none\")\n",
    "    post_pred = AsDiscrete(threshold=0.5)\n",
    "    post_label = AsDiscrete(threshold=0.5)\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_multi_masks = []  # Store multi-class masks for confusion matrix\n",
    "    \n",
    "    # Lists to store per-image metrics for visualization\n",
    "    dice_scores = []\n",
    "    hausdorff_distances = []\n",
    "    surface_dice_scores = []\n",
    "    \n",
    "    print(\"🧪 Running detection on test dataset...\")\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(dataset.test)):\n",
    "            sample = dataset.get_test_index(i, grayscale=grayscale, scharr=scharr)\n",
    "            if sample[0] is None:\n",
    "                continue\n",
    "            \n",
    "            image, bin_mask, multi_mask = sample\n",
    "            orig_size = image.shape[-2:]  # Save original size\n",
    "            \n",
    "            if scale_factor != 1:\n",
    "                image = F.interpolate(image.unsqueeze(0), scale_factor=1/scale_factor, mode='bilinear', align_corners=False)\n",
    "            else:\n",
    "                image = image.unsqueeze(0)\n",
    "            \n",
    "            bin_mask = bin_mask.unsqueeze(0).to(device)\n",
    "            image = image.to(device)\n",
    "            \n",
    "            pred = model(image)\n",
    "            if scale_factor != 1:\n",
    "                pred = F.interpolate(pred, size=orig_size, mode='bilinear', align_corners=False)\n",
    "            \n",
    "            pred_bin = post_pred(torch.sigmoid(pred))\n",
    "            label_bin = post_label(bin_mask)\n",
    "            \n",
    "            # Calculate per-image metrics\n",
    "            dice_val = dice_metric(pred_bin, label_bin).item()\n",
    "            hausdorff_val = hausdorff(pred_bin, label_bin).item()\n",
    "            surface_dice_val = surface_dice(pred_bin, label_bin).item()\n",
    "            \n",
    "            # Store metrics\n",
    "            dice_scores.append(dice_val)\n",
    "            hausdorff_distances.append(hausdorff_val)\n",
    "            surface_dice_scores.append(surface_dice_val)\n",
    "            \n",
    "            all_preds.append(pred_bin)\n",
    "            all_labels.append(label_bin)\n",
    "            all_multi_masks.append(multi_mask.unsqueeze(0))  # Keep multi-class mask\n",
    "            \n",
    "            del image, bin_mask, pred\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    preds_tensor = torch.cat(all_preds, dim=0)\n",
    "    labels_tensor = torch.cat(all_labels, dim=0)\n",
    "    multi_masks_tensor = torch.cat(all_multi_masks, dim=0)\n",
    "    \n",
    "    # Compute overall metrics (mean of per-image metrics)\n",
    "    mean_dice = np.mean(dice_scores)\n",
    "    mean_hausdorff = np.mean([h for h in hausdorff_distances if not np.isinf(h)])\n",
    "    mean_surface_dice = np.mean(surface_dice_scores)\n",
    "    \n",
    "    print(f\"\\n📊 Standard Metrics:\")\n",
    "    print(f\"🎯 Dice Score: {mean_dice:.4f} ± {np.std(dice_scores):.4f}\")\n",
    "    print(f\"📏 Hausdorff Distance (95th percentile): {mean_hausdorff:.4f} ± {np.std([h for h in hausdorff_distances if not np.isinf(h)]):.4f}\")\n",
    "    print(f\"🌊 Normalized Surface Dice: {mean_surface_dice:.4f} ± {np.std(surface_dice_scores):.4f}\")\n",
    "    \n",
    "    # Create metrics distribution plots\n",
    "    create_metrics_plots(dice_scores, hausdorff_distances, surface_dice_scores)\n",
    "    \n",
    "    # Create confusion matrix analysis\n",
    "    analyze_cell_type_confusion(preds_tensor, multi_masks_tensor)\n",
    "    \n",
    "    return mean_dice, mean_hausdorff, mean_surface_dice\n",
    "\n",
    "def create_metrics_plots(dice_scores, hausdorff_distances, surface_dice_scores):\n",
    "    \"\"\"\n",
    "    Create visualization plots for the three main metrics.\n",
    "    \"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    \n",
    "    # Dice Score distribution\n",
    "    if dice_scores:\n",
    "        axes[0].hist(dice_scores, bins=20, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "        axes[0].set_xlabel('Dice Score')\n",
    "        axes[0].set_ylabel('Number of Images')\n",
    "        axes[0].set_title('Distribution of Dice Scores')\n",
    "        axes[0].axvline(np.mean(dice_scores), color='red', linestyle='--', \n",
    "                       label=f'Mean: {np.mean(dice_scores):.3f}')\n",
    "        axes[0].legend()\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Hausdorff Distance distribution\n",
    "    if hausdorff_distances:\n",
    "        finite_hausdorff = [h for h in hausdorff_distances if not np.isinf(h)]\n",
    "        if finite_hausdorff:\n",
    "            axes[1].hist(finite_hausdorff, bins=20, alpha=0.7, color='lightcoral', edgecolor='black')\n",
    "            axes[1].set_xlabel('Hausdorff Distance')\n",
    "            axes[1].set_ylabel('Number of Images')\n",
    "            axes[1].set_title('Distribution of Hausdorff Distances')\n",
    "            axes[1].axvline(np.mean(finite_hausdorff), color='red', linestyle='--', \n",
    "                           label=f'Mean: {np.mean(finite_hausdorff):.3f}')\n",
    "            axes[1].legend()\n",
    "            axes[1].grid(True, alpha=0.3)\n",
    "        else:\n",
    "            axes[1].text(0.5, 0.5, 'No finite Hausdorff distances', \n",
    "                        transform=axes[1].transAxes, ha='center', va='center')\n",
    "            axes[1].set_title('Distribution of Hausdorff Distances')\n",
    "    \n",
    "    # Surface Dice distribution\n",
    "    if surface_dice_scores:\n",
    "        axes[2].hist(surface_dice_scores, bins=20, alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "        axes[2].set_xlabel('Surface Dice Score')\n",
    "        axes[2].set_ylabel('Number of Images')\n",
    "        axes[2].set_title('Distribution of Surface Dice Scores')\n",
    "        axes[2].axvline(np.mean(surface_dice_scores), color='red', linestyle='--', \n",
    "                       label=f'Mean: {np.mean(surface_dice_scores):.3f}')\n",
    "        axes[2].legend()\n",
    "        axes[2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print additional statistics\n",
    "    print(f\"\\n📈 Detailed Metrics Statistics:\")\n",
    "    print(\"=\" * 50)\n",
    "    if dice_scores:\n",
    "        print(f\"Dice Score - Min: {np.min(dice_scores):.3f}, Max: {np.max(dice_scores):.3f}, Median: {np.median(dice_scores):.3f}\")\n",
    "    \n",
    "    finite_hausdorff = [h for h in hausdorff_distances if not np.isinf(h)]\n",
    "    if finite_hausdorff:\n",
    "        print(f\"Hausdorff Distance - Min: {np.min(finite_hausdorff):.3f}, Max: {np.max(finite_hausdorff):.3f}, Median: {np.median(finite_hausdorff):.3f}\")\n",
    "    \n",
    "    if surface_dice_scores:\n",
    "        print(f\"Surface Dice - Min: {np.min(surface_dice_scores):.3f}, Max: {np.max(surface_dice_scores):.3f}, Median: {np.median(surface_dice_scores):.3f}\")\n",
    "\n",
    "def analyze_cell_type_confusion(preds_tensor, multi_masks_tensor):\n",
    "    \"\"\"\n",
    "    Analyze which cell types are being missed by the binary segmentation model\n",
    "    \"\"\"\n",
    "    print(f\"\\n🔍 Cell Type Detection Analysis:\")\n",
    "    \n",
    "    # Convert tensors to numpy and flatten\n",
    "    preds_np = preds_tensor.cpu().numpy().flatten()\n",
    "    multi_masks_np = multi_masks_tensor.cpu().numpy().flatten()\n",
    "    \n",
    "    # Cell type names (adjust according to your dataset)\n",
    "    cell_types = ['Background', 'Type 1', 'Type 2', 'Type 3', 'Type 4', \n",
    "                  'Type 5', 'Type 6', 'Type 7']\n",
    "    \n",
    "    # Create binary ground truth from multi-class (any non-zero = cell)\n",
    "    gt_binary = (multi_masks_np > 0).astype(int)\n",
    "    \n",
    "    # Statistics for each cell type\n",
    "    print(\"\\n📈 Detection Statistics by Cell Type:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    overall_stats = {\n",
    "        'cell_type': [],\n",
    "        'total_pixels': [],\n",
    "        'detected_pixels': [],\n",
    "        'detection_rate': [],\n",
    "        'false_positive_on_bg': 0,\n",
    "        'total_bg_pixels': 0\n",
    "    }\n",
    "    \n",
    "    for cell_type_id in range(len(cell_types)):\n",
    "        # Mask for current cell type\n",
    "        cell_mask = (multi_masks_np == cell_type_id)\n",
    "        total_pixels = cell_mask.sum()\n",
    "        \n",
    "        if cell_type_id == 0:  # Background\n",
    "            # For background, count false positives\n",
    "            false_positives = ((cell_mask) & (preds_np == 1)).sum()\n",
    "            overall_stats['false_positive_on_bg'] = false_positives\n",
    "            overall_stats['total_bg_pixels'] = total_pixels\n",
    "            print(f\"{cell_types[cell_type_id]:>10}: {total_pixels:>8} pixels | \"\n",
    "                  f\"False Positives: {false_positives:>6} ({100*false_positives/total_pixels:.2f}%)\")\n",
    "        else:  # Cell types\n",
    "            # For cell types, count true positives (correctly detected)\n",
    "            detected_pixels = ((cell_mask) & (preds_np == 1)).sum()\n",
    "            detection_rate = detected_pixels / total_pixels if total_pixels > 0 else 0\n",
    "            \n",
    "            overall_stats['cell_type'].append(cell_types[cell_type_id])\n",
    "            overall_stats['total_pixels'].append(total_pixels)\n",
    "            overall_stats['detected_pixels'].append(detected_pixels)\n",
    "            overall_stats['detection_rate'].append(detection_rate)\n",
    "            \n",
    "            print(f\"{cell_types[cell_type_id]:>10}: {total_pixels:>8} pixels | \"\n",
    "                  f\"Detected: {detected_pixels:>6} ({100*detection_rate:.2f}%)\")\n",
    "    \n",
    "    # Create confusion matrix visualization\n",
    "    create_confusion_matrix_plot(preds_np, multi_masks_np, cell_types)\n",
    "    \n",
    "    # Summary of poorly detected cell types\n",
    "    print(f\"\\n⚠️  Detection Performance Summary:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    detection_rates = overall_stats['detection_rate']\n",
    "    if detection_rates:\n",
    "        avg_detection_rate = np.mean(detection_rates)\n",
    "        print(f\"Average Detection Rate: {100*avg_detection_rate:.2f}%\")\n",
    "        \n",
    "        # Find poorly detected cell types (below average)\n",
    "        poor_detection_threshold = avg_detection_rate * 0.8  # 80% of average\n",
    "        poorly_detected = []\n",
    "        \n",
    "        for i, (cell_type, rate) in enumerate(zip(overall_stats['cell_type'], detection_rates)):\n",
    "            if rate < poor_detection_threshold:\n",
    "                poorly_detected.append((cell_type, rate))\n",
    "        \n",
    "        if poorly_detected:\n",
    "            print(f\"\\n🚨 Cell types with poor detection (< {100*poor_detection_threshold:.1f}%):\")\n",
    "            for cell_type, rate in poorly_detected:\n",
    "                print(f\"   • {cell_type}: {100*rate:.2f}%\")\n",
    "        else:\n",
    "            print(\"✅ All cell types have reasonable detection rates!\")\n",
    "    \n",
    "    # Background false positive analysis\n",
    "    bg_fp_rate = overall_stats['false_positive_on_bg'] / overall_stats['total_bg_pixels']\n",
    "    print(f\"\\n🎭 Background False Positive Rate: {100*bg_fp_rate:.2f}%\")\n",
    "    \n",
    "    return overall_stats\n",
    "\n",
    "def create_confusion_matrix_plot(preds_np, multi_masks_np, cell_types):\n",
    "    \"\"\"\n",
    "    Create a confusion matrix plot showing binary prediction vs multi-class ground truth\n",
    "    \"\"\"\n",
    "    # Create a modified ground truth for visualization\n",
    "    # 0 = background, 1-8 = cell types, but we'll group cell types\n",
    "    gt_for_confusion = multi_masks_np.copy()\n",
    "    \n",
    "    # For confusion matrix, we want to see:\n",
    "    # - Background correctly classified as background (TN)\n",
    "    # - Background incorrectly classified as cell (FP)  \n",
    "    # - Each cell type correctly classified as cell (TP)\n",
    "    # - Each cell type incorrectly classified as background (FN)\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Plot 1: Detailed confusion matrix (background vs each cell type)\n",
    "    confusion_detailed = np.zeros((len(cell_types), 2))  # [cell_types x 2] (pred_bg, pred_cell)\n",
    "    \n",
    "    for cell_type_id in range(len(cell_types)):\n",
    "        cell_mask = (multi_masks_np == cell_type_id)\n",
    "        \n",
    "        # Count predictions for this cell type\n",
    "        pred_bg_count = ((cell_mask) & (preds_np == 0)).sum()\n",
    "        pred_cell_count = ((cell_mask) & (preds_np == 1)).sum()\n",
    "        \n",
    "        confusion_detailed[cell_type_id, 0] = pred_bg_count\n",
    "        confusion_detailed[cell_type_id, 1] = pred_cell_count\n",
    "    \n",
    "    # Normalize by row to show percentages\n",
    "    confusion_detailed_pct = confusion_detailed / (confusion_detailed.sum(axis=1, keepdims=True) + 1e-8)\n",
    "    \n",
    "    sns.heatmap(confusion_detailed_pct, \n",
    "                xticklabels=['Pred: Background', 'Pred: Cell'],\n",
    "                yticklabels=cell_types,\n",
    "                annot=True, \n",
    "                fmt='.3f',\n",
    "                cmap='Blues',\n",
    "                ax=ax1)\n",
    "    ax1.set_title('Detection Rate by Cell Type\\n(Row-normalized)')\n",
    "    ax1.set_ylabel('True Cell Type')\n",
    "    \n",
    "    # Plot 2: Simple 2x2 confusion matrix (Binary: Cell vs Background)\n",
    "    gt_binary = (multi_masks_np > 0).astype(int)\n",
    "    cm_binary = confusion_matrix(gt_binary, preds_np)\n",
    "    \n",
    "    sns.heatmap(cm_binary, \n",
    "                xticklabels=['Pred: Background', 'Pred: Cell'],\n",
    "                yticklabels=['True: Background', 'True: Cell'],\n",
    "                annot=True, \n",
    "                fmt='d',\n",
    "                cmap='Blues',\n",
    "                ax=ax2)\n",
    "    ax2.set_title('Binary Confusion Matrix\\n(Cell vs Background)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print binary confusion matrix metrics\n",
    "    tn, fp, fn, tp = cm_binary.ravel()\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    print(f\"\\n📋 Binary Classification Metrics:\")\n",
    "    print(f\"   Precision (Cell): {precision:.4f}\")\n",
    "    print(f\"   Recall (Cell):    {recall:.4f}\")\n",
    "    print(f\"   F1-Score:         {f1:.4f}\")\n",
    "    print(f\"   True Positives:   {tp:,}\")\n",
    "    print(f\"   False Positives:  {fp:,}\")\n",
    "    print(f\"   False Negatives:  {fn:,}\")\n",
    "    print(f\"   True Negatives:   {tn:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586c8b11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T11:08:27.339796Z",
     "iopub.status.busy": "2025-06-17T11:08:27.339516Z",
     "iopub.status.idle": "2025-06-17T11:08:27.391455Z",
     "shell.execute_reply": "2025-06-17T11:08:27.390895Z",
     "shell.execute_reply.started": "2025-06-17T11:08:27.339774Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = CellDataSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507cfb99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T10:41:12.346789Z",
     "iopub.status.busy": "2025-06-13T10:41:12.346240Z",
     "iopub.status.idle": "2025-06-13T10:43:32.126881Z",
     "shell.execute_reply": "2025-06-13T10:43:32.126069Z",
     "shell.execute_reply.started": "2025-06-13T10:41:12.346770Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_detector(dataset, model_class=GrUnetArhitecture,scale_factor=2, model_path=\"SC2BUGF015Dice07BC015.pth\", grayscale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8721a3e4",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-13T10:48:24.900892Z",
     "iopub.status.busy": "2025-06-13T10:48:24.900388Z",
     "iopub.status.idle": "2025-06-13T10:51:15.045598Z",
     "shell.execute_reply": "2025-06-13T10:51:15.044760Z",
     "shell.execute_reply.started": "2025-06-13T10:48:24.900867Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_detector(dataset, model_class=GrUnetArhitecture, model_path=\"BUGF05Dice05BC05.pth\", grayscale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b584f75a",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-13T10:52:28.111625Z",
     "iopub.status.busy": "2025-06-13T10:52:28.111355Z",
     "iopub.status.idle": "2025-06-13T10:54:49.212796Z",
     "shell.execute_reply": "2025-06-13T10:54:49.212167Z",
     "shell.execute_reply.started": "2025-06-13T10:52:28.111606Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_detector(dataset, model_class=GrayScaleSmallerUnet, model_path=\"smaller_unet.pth\", grayscale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a40981",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T11:12:18.496075Z",
     "iopub.status.busy": "2025-06-17T11:12:18.495760Z",
     "iopub.status.idle": "2025-06-17T11:14:45.511660Z",
     "shell.execute_reply": "2025-06-17T11:14:45.510787Z",
     "shell.execute_reply.started": "2025-06-17T11:12:18.496054Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_detector(dataset, model_class=GrayScaleMediumUnet, model_path=\"dice_medium.pth\", grayscale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789a873b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T11:15:38.938269Z",
     "iopub.status.busy": "2025-06-17T11:15:38.937509Z",
     "iopub.status.idle": "2025-06-17T11:18:03.794420Z",
     "shell.execute_reply": "2025-06-17T11:18:03.793409Z",
     "shell.execute_reply.started": "2025-06-17T11:15:38.938245Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_detector(dataset, model_class=GrayScaleSmallerUnet, model_path=\"F05Dice05H0002L4Small2.pth\", grayscale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4053fbed",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-17T11:08:30.542123Z",
     "iopub.status.busy": "2025-06-17T11:08:30.541413Z",
     "iopub.status.idle": "2025-06-17T11:11:41.639471Z",
     "shell.execute_reply": "2025-06-17T11:11:41.638828Z",
     "shell.execute_reply.started": "2025-06-17T11:08:30.542096Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_detector(dataset, model_class=UnetArhitecture, model_path=\"dice_unet.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8369d5a",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-13T11:00:48.568521Z",
     "iopub.status.busy": "2025-06-13T11:00:48.567923Z",
     "iopub.status.idle": "2025-06-13T11:03:07.794761Z",
     "shell.execute_reply": "2025-06-13T11:03:07.793982Z",
     "shell.execute_reply.started": "2025-06-13T11:00:48.568495Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_detector(dataset, model_class=GrayScaleMediumUnet, model_path=\"dice_HDmedium.pth\",grayscale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca95be5d",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-13T11:07:35.482629Z",
     "iopub.status.busy": "2025-06-13T11:07:35.481896Z",
     "iopub.status.idle": "2025-06-13T11:09:55.786673Z",
     "shell.execute_reply": "2025-06-13T11:09:55.785952Z",
     "shell.execute_reply.started": "2025-06-13T11:07:35.482606Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_detector(dataset, model_class=GrayScaleMediumUnet, model_path=\"dice_MultiLossMedium.pth\",grayscale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdb13ec",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-13T11:10:22.422107Z",
     "iopub.status.busy": "2025-06-13T11:10:22.421548Z",
     "iopub.status.idle": "2025-06-13T11:15:02.492390Z",
     "shell.execute_reply": "2025-06-13T11:15:02.491379Z",
     "shell.execute_reply.started": "2025-06-13T11:10:22.422084Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_detector(dataset, model_class=GrayScaleSmallerUnet, model_path=\"GrayCr07Dice03Small.pth\",grayscale=True)\n",
    "test_detector(dataset, model_class=GrayScaleSmallerUnet, model_path=\"GrayCr03Dice06H0001Small.pth\",grayscale=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4930c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T17:58:05.579588Z",
     "iopub.status.busy": "2025-06-13T17:58:05.579285Z",
     "iopub.status.idle": "2025-06-13T17:58:06.182709Z",
     "shell.execute_reply": "2025-06-13T17:58:06.182035Z",
     "shell.execute_reply.started": "2025-06-13T17:58:05.579564Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd41d75a",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-13T11:17:37.419232Z",
     "iopub.status.busy": "2025-06-13T11:17:37.418514Z",
     "iopub.status.idle": "2025-06-13T11:31:25.361647Z",
     "shell.execute_reply": "2025-06-13T11:31:25.360595Z",
     "shell.execute_reply.started": "2025-06-13T11:17:37.419208Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_detector(dataset, model_class=SmallerUnet, model_path=\"Cr07Dice03Small.pth\")\n",
    "test_detector(dataset, model_class=Layer4GrayScaleSmallerUnet, model_path=\"Cr07Dice03L4Small.pth\", grayscale=True)\n",
    "test_detector(dataset, model_class=Layer4GrayScaleSmallerUnet, model_path=\"Cr07Dice03L4Small2.pth\", grayscale=True)\n",
    "test_detector(dataset, model_class=Layer4GrayScaleSmallerUnet, model_path=\"CDH05_0005.pth\", grayscale=True)\n",
    "test_detector(dataset, model_class=GrayScaleSmallerUnet, model_path=\"F05Dice05H0002L4Small2.pth\", grayscale=True)\n",
    "test_detector(dataset, model_class=GrayScaleSmallerUnet, model_path=\"F07Dice03H0002L4Small2.pth\", grayscale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd77647",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-13T11:32:04.987769Z",
     "iopub.status.busy": "2025-06-13T11:32:04.987072Z",
     "iopub.status.idle": "2025-06-13T11:36:40.420887Z",
     "shell.execute_reply": "2025-06-13T11:36:40.420124Z",
     "shell.execute_reply.started": "2025-06-13T11:32:04.987738Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_detector(dataset, model_class=GrayScaleSmallerUnet, model_path=\"F07Dice03H0002L4Small2.pth\", grayscale=True)\n",
    "test_detector(dataset, model_class=GrayScaleSmallerUnet, model_path=\"F05Dice05BC052.pth\", grayscale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872665d3",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-13T21:46:45.357599Z",
     "iopub.status.busy": "2025-06-13T21:46:45.357324Z",
     "iopub.status.idle": "2025-06-13T22:06:20.991860Z",
     "shell.execute_reply": "2025-06-13T22:06:20.991047Z",
     "shell.execute_reply.started": "2025-06-13T21:46:45.357572Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = CellDataSet()\n",
    "model = Layer4GrayScaleSmallerUnet()\n",
    "model.load_state_dict(torch.load(\"L4F04D06H0003.pth\")) \n",
    "train_model(model, dataset, num_epochs=80, grayscale=True, save_path=\"L4F04D06H0003.pth\")\n",
    "test_detector(dataset, model_class=Layer4GrayScaleSmallerUnet, model_path=\"L4F04D06H0003.pth\", grayscale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5755f422",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-14T03:29:31.800251Z",
     "iopub.status.busy": "2025-06-14T03:29:31.799836Z",
     "iopub.status.idle": "2025-06-14T05:31:12.870372Z",
     "shell.execute_reply": "2025-06-14T05:31:12.868986Z",
     "shell.execute_reply.started": "2025-06-14T03:29:31.800221Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "gc.collect()\n",
    "dataset = CellDataSet()\n",
    "try:\n",
    "    model = GrayScaleSmallerUnet()\n",
    "    train_model(model, dataset, num_epochs=80, grayscale=True, save_path=\"SF04D06H0003.pth\")\n",
    "    test_detector(dataset, model_class=GrayScaleSmallerUnet, model_path=\"SF04D06H0003.pth\", grayscale=True)\n",
    "except:\n",
    "    print(\"An exception occurred\")\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    model = GrayScaleSmallerUnet()\n",
    "    model.load_state_dict(torch.load(\"SF04D06H0003.pth\")) \n",
    "    train_model(model, dataset, num_epochs=80, grayscale=True, save_path=\"SF04D06H0003.pth\")\n",
    "    test_detector(dataset, model_class=GrayScaleSmallerUnet, model_path=\"SF04D06H0003.pth\", grayscale=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcab995",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-15T05:10:46.461231Z",
     "iopub.status.busy": "2025-06-15T05:10:46.460671Z",
     "iopub.status.idle": "2025-06-15T05:48:36.583655Z",
     "shell.execute_reply": "2025-06-15T05:48:36.582487Z",
     "shell.execute_reply.started": "2025-06-15T05:10:46.461209Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "dataset = CellDataSet()\n",
    "model = GrayScaleSmallerUnet()\n",
    "model.load_state_dict(torch.load(\"SF04D06H0003.pth\")) \n",
    "train_model(model, dataset, num_epochs=80, grayscale=True, save_path=\"SF04D06H0003.pth\")\n",
    "test_detector(dataset, model_class=GrayScaleSmallerUnet, model_path=\"SF04D06H0003.pth\", grayscale=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb8c687",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-15T08:40:36.145508Z",
     "iopub.status.busy": "2025-06-15T08:40:36.145203Z",
     "iopub.status.idle": "2025-06-15T09:11:27.959434Z",
     "shell.execute_reply": "2025-06-15T09:11:27.958638Z",
     "shell.execute_reply.started": "2025-06-15T08:40:36.145488Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "test_detector(dataset, model_class=GrayScaleMediumUnet, model_path=\"MF05D05H0002v2.pth\", grayscale=True)\n",
    "model = GrayScaleMediumUnet()\n",
    "model.load_state_dict(torch.load(\"MF05D05H0002v2.pth\")) \n",
    "train_model(model, dataset, num_epochs=80, grayscale=True, save_path=\"MF05D05H0002v3.pth\")\n",
    "test_detector(dataset, model_class=GrayScaleMediumUnet, model_path=\"MF05D05H0002v3.pth\", grayscale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00945ea",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-15T09:23:44.905765Z",
     "iopub.status.busy": "2025-06-15T09:23:44.905063Z",
     "iopub.status.idle": "2025-06-15T11:13:51.732587Z",
     "shell.execute_reply": "2025-06-15T11:13:51.731773Z",
     "shell.execute_reply.started": "2025-06-15T09:23:44.905740Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "model = GrayScaleMediumUnet()\n",
    "train_model(model, dataset, num_epochs=80, grayscale=True, save_path=\"MF05D05H0002NoAUG.pth\")\n",
    "test_detector(dataset, model_class=GrayScaleMediumUnet, model_path=\"MF05D05H0002NoAUG.pth\", grayscale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2106730f",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-16T16:20:16.449841Z",
     "iopub.status.busy": "2025-06-16T16:20:16.446343Z",
     "iopub.status.idle": "2025-06-16T18:23:09.004647Z",
     "shell.execute_reply": "2025-06-16T18:23:09.003619Z",
     "shell.execute_reply.started": "2025-06-16T16:20:16.449766Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import gc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from pathlib import Path\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from monai.metrics import DiceMetric, HausdorffDistanceMetric, SurfaceDistanceMetric\n",
    "from monai.transforms import AsDiscrete\n",
    "\n",
    "def dbscan_cell_detection(image_path, color_eps=0.1, color_min_samples=3, \n",
    "                         spatial_eps=0.005, spatial_min_samples=80, visualize=False):\n",
    "    \"\"\"\n",
    "    Apply DBSCAN-based cell detection to a single image.\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to the input image\n",
    "        color_eps: DBSCAN epsilon for color clustering\n",
    "        color_min_samples: DBSCAN min_samples for color clustering\n",
    "        spatial_eps: DBSCAN epsilon for spatial clustering\n",
    "        spatial_min_samples: DBSCAN min_samples for spatial clustering\n",
    "        visualize: Whether to show intermediate visualizations\n",
    "    \n",
    "    Returns:\n",
    "        mask_grayscale: Binary mask of detected cells\n",
    "        stats: Dictionary with detection statistics\n",
    "    \"\"\"\n",
    "    # Read image\n",
    "    picture = np.array(cv2.imread(image_path, cv2.IMREAD_COLOR))\n",
    "    if picture is None:\n",
    "        return None, None\n",
    "    \n",
    "    original_picture = picture.copy()\n",
    "    original_shape = picture.shape\n",
    "    \n",
    "    # Step 1: Color-based clustering to remove background\n",
    "    picture_reshaped = picture.reshape((picture.shape[0] * picture.shape[1], picture.shape[2]))\n",
    "    \n",
    "    # Apply DBSCAN on color space\n",
    "    dbscan_color = DBSCAN(eps=color_eps, min_samples=color_min_samples)\n",
    "    color_labels = dbscan_color.fit_predict(picture_reshaped)\n",
    "    \n",
    "    # Create mask - set background (noise) to black\n",
    "    color_mask = np.array(picture_reshaped)\n",
    "    color_mask[color_labels != -1] = np.array([0, 0, 0])\n",
    "    color_mask = color_mask.reshape(original_shape)\n",
    "    color_mask = color_mask.astype(np.uint8)\n",
    "    \n",
    "    if visualize:\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(cv2.cvtColor(original_picture, cv2.COLOR_BGR2RGB))\n",
    "        plt.title('Original Image')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(cv2.cvtColor(color_mask, cv2.COLOR_BGR2RGB))\n",
    "        plt.title('After Color Clustering')\n",
    "        plt.axis('off')\n",
    "    \n",
    "    # Step 2: Spatial clustering on remaining pixels\n",
    "    cells = np.argwhere(np.any(color_mask != [0, 0, 0], axis=-1))\n",
    "    \n",
    "    if len(cells) == 0:\n",
    "        # No cells detected\n",
    "        mask_grayscale = np.zeros(original_shape[:2], dtype=np.uint8)\n",
    "        stats = {\n",
    "            'total_pixels': original_shape[0] * original_shape[1],\n",
    "            'background_pixels': original_shape[0] * original_shape[1],\n",
    "            'cell_pixels': 0,\n",
    "            'detected_clusters': 0,\n",
    "            'noise_pixels': 0\n",
    "        }\n",
    "        return mask_grayscale, stats\n",
    "    \n",
    "    # Normalize pixel coordinates\n",
    "    normalized_pixels = cells / np.array(original_shape[0:2])\n",
    "    \n",
    "    # Apply DBSCAN on spatial coordinates\n",
    "    dbscan_spatial = DBSCAN(eps=spatial_eps, min_samples=spatial_min_samples)\n",
    "    spatial_labels = dbscan_spatial.fit_predict(normalized_pixels)\n",
    "    \n",
    "    # Create final mask\n",
    "    cells_valid = cells[spatial_labels != -1]\n",
    "    spatial_labels_valid = spatial_labels[spatial_labels != -1]\n",
    "    \n",
    "    mask_grayscale = np.zeros(original_shape[:2], dtype=np.uint8)\n",
    "    if len(cells_valid) > 0:\n",
    "        mask_grayscale[cells_valid[:, 0], cells_valid[:, 1]] = 255\n",
    "    \n",
    "    if visualize:\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(mask_grayscale, cmap='gray')\n",
    "        plt.title('Final Cell Detection')\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # Calculate statistics\n",
    "    total_pixels = original_shape[0] * original_shape[1]\n",
    "    cell_pixels = len(cells_valid)\n",
    "    noise_pixels = len(cells) - len(cells_valid) if len(cells) > 0 else 0\n",
    "    background_pixels = total_pixels - len(cells)\n",
    "    detected_clusters = len(np.unique(spatial_labels_valid)) if len(spatial_labels_valid) > 0 else 0\n",
    "    \n",
    "    stats = {\n",
    "        'total_pixels': total_pixels,\n",
    "        'background_pixels': background_pixels,\n",
    "        'cell_pixels': cell_pixels,\n",
    "        'detected_clusters': detected_clusters,\n",
    "        'noise_pixels': noise_pixels,\n",
    "        'detection_rate': cell_pixels / total_pixels,\n",
    "        'cluster_efficiency': cell_pixels / len(cells) if len(cells) > 0 else 0\n",
    "    }\n",
    "    \n",
    "    return mask_grayscale, stats\n",
    "\n",
    "def compute_advanced_metrics(pred_mask, gt_mask):\n",
    "    \"\"\"\n",
    "    Compute Dice score, Hausdorff distance, and Surface Dice using MONAI metrics.\n",
    "    \n",
    "    Args:\n",
    "        pred_mask: Predicted binary mask (H, W)\n",
    "        gt_mask: Ground truth binary mask (H, W)\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary containing the three metrics\n",
    "    \"\"\"\n",
    "    # Convert to torch tensors and add batch and channel dimensions\n",
    "    pred_tensor = torch.tensor(pred_mask, dtype=torch.float32).unsqueeze(0).unsqueeze(0)  # (1, 1, H, W)\n",
    "    gt_tensor = torch.tensor(gt_mask, dtype=torch.float32).unsqueeze(0).unsqueeze(0)      # (1, 1, H, W)\n",
    "    \n",
    "    # Ensure binary masks (0 or 1)\n",
    "    pred_tensor = (pred_tensor > 0.5).float()\n",
    "    gt_tensor = (gt_tensor > 0.5).float()\n",
    "    \n",
    "    # Initialize MONAI metrics\n",
    "    dice_metric = DiceMetric(include_background=False, reduction=\"mean\")\n",
    "    hausdorff_metric = HausdorffDistanceMetric(include_background=False, percentile=95)\n",
    "    surface_dice_metric = SurfaceDistanceMetric(include_background=False, symmetric=True)\n",
    "    \n",
    "    try:\n",
    "        # Compute metrics\n",
    "        dice_score = dice_metric(pred_tensor, gt_tensor).item()\n",
    "        hausdorff_dist = hausdorff_metric(pred_tensor, gt_tensor).item()\n",
    "        surface_dice = surface_dice_metric(pred_tensor, gt_tensor).item()\n",
    "        \n",
    "        # Handle edge cases\n",
    "        if np.isnan(dice_score) or np.isinf(dice_score):\n",
    "            dice_score = 0.0\n",
    "        if np.isnan(hausdorff_dist) or np.isinf(hausdorff_dist):\n",
    "            hausdorff_dist = float('inf')\n",
    "        if np.isnan(surface_dice) or np.isinf(surface_dice):\n",
    "            surface_dice = 0.0\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Error computing metrics: {e}\")\n",
    "        dice_score = 0.0\n",
    "        hausdorff_dist = float('inf')\n",
    "        surface_dice = 0.0\n",
    "    gc.collect()\n",
    "    return {\n",
    "        'dice_score': dice_score,\n",
    "        'hausdorff_distance': hausdorff_dist,\n",
    "        'surface_dice': surface_dice\n",
    "    }\n",
    "\n",
    "def analyze_cell_type_detection(pred_mask, multi_mask, cell_types=None):\n",
    "    \"\"\"\n",
    "    Analyze detection performance for each cell type using multi-class ground truth.\n",
    "    \n",
    "    Args:\n",
    "        pred_mask: Binary prediction mask (H, W)\n",
    "        multi_mask: Multi-class ground truth mask (H, W)\n",
    "        cell_types: List of cell type names\n",
    "    \n",
    "    Returns:\n",
    "        dict: Detection statistics for each cell type\n",
    "    \"\"\"\n",
    "    if cell_types is None:\n",
    "        unique_labels = np.unique(multi_mask)\n",
    "        cell_types = [f'Type_{i}' if i > 0 else 'Background' for i in unique_labels]\n",
    "    \n",
    "    # Ensure binary prediction mask\n",
    "    pred_binary = (pred_mask > 0).astype(int)\n",
    "    \n",
    "    cell_type_stats = {}\n",
    "    \n",
    "    for cell_type_id in np.unique(multi_mask):\n",
    "        cell_name = cell_types[cell_type_id] if cell_type_id < len(cell_types) else f'Type_{cell_type_id}'\n",
    "        \n",
    "        # Mask for current cell type\n",
    "        cell_mask = (multi_mask == cell_type_id)\n",
    "        total_pixels = cell_mask.sum()\n",
    "        \n",
    "        if cell_type_id == 0:  # Background\n",
    "            # For background, count false positives\n",
    "            detected_pixels = ((cell_mask) & (pred_binary == 1)).sum()\n",
    "            detection_rate = detected_pixels / total_pixels if total_pixels > 0 else 0\n",
    "            cell_type_stats[cell_name] = {\n",
    "                'total_pixels': total_pixels,\n",
    "                'false_positives': detected_pixels,\n",
    "                'false_positive_rate': detection_rate\n",
    "            }\n",
    "        else:  # Cell types\n",
    "            # For cell types, count true positives\n",
    "            detected_pixels = ((cell_mask) & (pred_binary == 1)).sum()\n",
    "            detection_rate = detected_pixels / total_pixels if total_pixels > 0 else 0\n",
    "            cell_type_stats[cell_name] = {\n",
    "                'total_pixels': total_pixels,\n",
    "                'detected_pixels': detected_pixels,\n",
    "                'detection_rate': detection_rate\n",
    "            }\n",
    "    \n",
    "    return cell_type_stats\n",
    "\n",
    "def test_dbscan_detector(image_folder, bin_mask_folder, mult_mask_folder,\n",
    "                        color_eps=0.1, color_min_samples=3,\n",
    "                        spatial_eps=0.005, spatial_min_samples=80,\n",
    "                        file_pattern=\"*.tif\", visualize_samples=3,\n",
    "                        cell_types=None):\n",
    "    \"\"\"\n",
    "    Test DBSCAN detector with advanced metrics similar to the UNet test function.\n",
    "    \n",
    "    Args:\n",
    "        image_folder: Path to folder containing test images\n",
    "        bin_mask_folder: Path to binary ground truth masks\n",
    "        mult_mask_folder: Path to multi-class ground truth masks\n",
    "        color_eps, color_min_samples: DBSCAN parameters for color clustering\n",
    "        spatial_eps, spatial_min_samples: DBSCAN parameters for spatial clustering\n",
    "        file_pattern: File pattern to match\n",
    "        visualize_samples: Number of samples to visualize\n",
    "        cell_types: List of cell type names for analysis\n",
    "    \n",
    "    Returns:\n",
    "        dict: Comprehensive test results\n",
    "    \"\"\"\n",
    "    \n",
    "    image_folder = Path(image_folder)\n",
    "    bin_mask_folder = Path(bin_mask_folder) if bin_mask_folder else None\n",
    "    mult_mask_folder = Path(mult_mask_folder) if mult_mask_folder else None\n",
    "    \n",
    "    if not image_folder.exists():\n",
    "        print(f\"❌ Image folder {image_folder} does not exist!\")\n",
    "        return None\n",
    "    \n",
    "    # Get all image files\n",
    "    image_files = list(image_folder.glob(file_pattern))\n",
    "    if not image_files:\n",
    "        print(f\"❌ No files matching pattern '{file_pattern}' found in {image_folder}\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"🧪 Testing DBSCAN detector on {len(image_files)} images...\")\n",
    "    print(f\"📁 Images: {image_folder}\")\n",
    "    print(f\"📁 Binary masks: {bin_mask_folder}\")\n",
    "    print(f\"📁 Multi-class masks: {mult_mask_folder}\")\n",
    "    print(f\"⚙️  Parameters: color_eps={color_eps}, spatial_eps={spatial_eps}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Initialize storage for results\n",
    "    all_dice_scores = []\n",
    "    all_hausdorff_distances = []\n",
    "    all_surface_dice_scores = []\n",
    "    all_cell_type_stats = []\n",
    "    all_image_stats = []\n",
    "    \n",
    "    # Process each image\n",
    "    for i, image_path in enumerate(tqdm(image_files, desc=\"Processing images\")):\n",
    "        \n",
    "        # Show visualization for first few samples\n",
    "        show_viz = i < visualize_samples\n",
    "        \n",
    "        # Run DBSCAN detection\n",
    "        pred_mask, basic_stats = dbscan_cell_detection(\n",
    "            str(image_path), \n",
    "            color_eps=color_eps,\n",
    "            color_min_samples=color_min_samples,\n",
    "            spatial_eps=spatial_eps,\n",
    "            spatial_min_samples=spatial_min_samples,\n",
    "            visualize=show_viz\n",
    "        )\n",
    "        \n",
    "        if pred_mask is None:\n",
    "            print(f\"⚠️  Failed to process {image_path.name}\")\n",
    "            continue\n",
    "        \n",
    "        image_results = {\n",
    "            'filename': image_path.name,\n",
    "            'basic_stats': basic_stats\n",
    "        }\n",
    "        \n",
    "        # Load and process ground truth masks\n",
    "        if bin_mask_folder:\n",
    "            bin_gt_path = bin_mask_folder / image_path.name\n",
    "            if bin_gt_path.exists():\n",
    "                bin_gt_mask = cv2.imread(str(bin_gt_path), cv2.IMREAD_GRAYSCALE)\n",
    "                if bin_gt_mask is not None:\n",
    "                    # Convert to binary (0 or 1)\n",
    "                    bin_gt_mask = (bin_gt_mask > 0).astype(np.uint8)\n",
    "                    \n",
    "                    # Compute advanced metrics\n",
    "                    metrics = compute_advanced_metrics(pred_mask, bin_gt_mask)\n",
    "                    image_results['metrics'] = metrics\n",
    "                    \n",
    "                    all_dice_scores.append(metrics['dice_score'])\n",
    "                    all_hausdorff_distances.append(metrics['hausdorff_distance'])\n",
    "                    all_surface_dice_scores.append(metrics['surface_dice'])\n",
    "                    \n",
    "                    if show_viz:\n",
    "                        # Show comparison\n",
    "                        plt.figure(figsize=(15, 5))\n",
    "                        plt.subplot(1, 3, 1)\n",
    "                        plt.imshow(pred_mask, cmap='gray')\n",
    "                        plt.title(f'DBSCAN Prediction\\n{image_path.name}')\n",
    "                        plt.axis('off')\n",
    "                        \n",
    "                        plt.subplot(1, 3, 2)\n",
    "                        plt.imshow(bin_gt_mask, cmap='gray')\n",
    "                        plt.title('Ground Truth')\n",
    "                        plt.axis('off')\n",
    "                        \n",
    "                        plt.subplot(1, 3, 3)\n",
    "                        plt.imshow(pred_mask, cmap='Reds', alpha=0.7)\n",
    "                        plt.imshow(bin_gt_mask, cmap='Blues', alpha=0.3)\n",
    "                        plt.title(f'Overlay\\nDice: {metrics[\"dice_score\"]:.3f}')\n",
    "                        plt.axis('off')\n",
    "                        plt.tight_layout()\n",
    "                        plt.show()\n",
    "        \n",
    "        # Analyze cell type detection\n",
    "        if mult_mask_folder:\n",
    "            mult_gt_path = mult_mask_folder / image_path.name\n",
    "            if mult_gt_path.exists():\n",
    "                mult_gt_mask = cv2.imread(str(mult_gt_path), cv2.IMREAD_GRAYSCALE)\n",
    "                if mult_gt_mask is not None:\n",
    "                    cell_type_stats = analyze_cell_type_detection(pred_mask, mult_gt_mask, cell_types)\n",
    "                    image_results['cell_type_stats'] = cell_type_stats\n",
    "                    all_cell_type_stats.append(cell_type_stats)\n",
    "        \n",
    "        all_image_stats.append(image_results)\n",
    "    \n",
    "    # Print comprehensive results\n",
    "    print_comprehensive_results(all_dice_scores, all_hausdorff_distances, all_surface_dice_scores, \n",
    "                               all_cell_type_stats, all_image_stats)\n",
    "    \n",
    "    return {\n",
    "        'dice_scores': all_dice_scores,\n",
    "        'hausdorff_distances': all_hausdorff_distances,\n",
    "        'surface_dice_scores': all_surface_dice_scores,\n",
    "        'cell_type_stats': all_cell_type_stats,\n",
    "        'image_stats': all_image_stats\n",
    "    }\n",
    "\n",
    "def print_comprehensive_results(dice_scores, hausdorff_distances, surface_dice_scores, \n",
    "                               cell_type_stats, image_stats):\n",
    "    \"\"\"\n",
    "    Print comprehensive test results similar to UNet test function.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n📊 DBSCAN Cell Detection Test Results\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Standard metrics\n",
    "    if dice_scores:\n",
    "        avg_dice = np.mean(dice_scores)\n",
    "        std_dice = np.std(dice_scores)\n",
    "        print(f\"🎯 Dice Score: {avg_dice:.4f} ± {std_dice:.4f}\")\n",
    "        print(f\"   Range: {min(dice_scores):.4f} - {max(dice_scores):.4f}\")\n",
    "    \n",
    "    if hausdorff_distances:\n",
    "        # Filter out infinite values for statistics\n",
    "        finite_hausdorff = [h for h in hausdorff_distances if not np.isinf(h)]\n",
    "        if finite_hausdorff:\n",
    "            avg_hausdorff = np.mean(finite_hausdorff)\n",
    "            std_hausdorff = np.std(finite_hausdorff)\n",
    "            print(f\"📏 Hausdorff Distance (95th percentile): {avg_hausdorff:.4f} ± {std_hausdorff:.4f}\")\n",
    "            print(f\"   Range: {min(finite_hausdorff):.4f} - {max(finite_hausdorff):.4f}\")\n",
    "            if len(finite_hausdorff) < len(hausdorff_distances):\n",
    "                print(f\"   Note: {len(hausdorff_distances) - len(finite_hausdorff)} images had infinite Hausdorff distance\")\n",
    "    \n",
    "    if surface_dice_scores:\n",
    "        avg_surface_dice = np.mean(surface_dice_scores)\n",
    "        std_surface_dice = np.std(surface_dice_scores)\n",
    "        print(f\"🌊 Normalized Surface Dice: {avg_surface_dice:.4f} ± {std_surface_dice:.4f}\")\n",
    "        print(f\"   Range: {min(surface_dice_scores):.4f} - {max(surface_dice_scores):.4f}\")\n",
    "    \n",
    "    # Cell type analysis\n",
    "    if cell_type_stats:\n",
    "        print(f\"\\n🔍 Cell Type Detection Analysis:\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Aggregate cell type statistics\n",
    "        cell_type_summary = {}\n",
    "        for stats in cell_type_stats:\n",
    "            for cell_type, type_stats in stats.items():\n",
    "                if cell_type not in cell_type_summary:\n",
    "                    cell_type_summary[cell_type] = {\n",
    "                        'total_pixels': [],\n",
    "                        'detected_pixels': [] if 'detected_pixels' in type_stats else [],\n",
    "                        'detection_rates': [] if 'detection_rate' in type_stats else [],\n",
    "                        'false_positive_rates': [] if 'false_positive_rate' in type_stats else []\n",
    "                    }\n",
    "                \n",
    "                cell_type_summary[cell_type]['total_pixels'].append(type_stats['total_pixels'])\n",
    "                if 'detected_pixels' in type_stats:\n",
    "                    cell_type_summary[cell_type]['detected_pixels'].append(type_stats['detected_pixels'])\n",
    "                    cell_type_summary[cell_type]['detection_rates'].append(type_stats['detection_rate'])\n",
    "                if 'false_positive_rate' in type_stats:\n",
    "                    cell_type_summary[cell_type]['false_positive_rates'].append(type_stats['false_positive_rate'])\n",
    "        \n",
    "        # Print summary for each cell type\n",
    "        for cell_type, summary in cell_type_summary.items():\n",
    "            total_pixels = sum(summary['total_pixels'])\n",
    "            \n",
    "            if cell_type == 'Background':\n",
    "                if summary['false_positive_rates']:\n",
    "                    avg_fp_rate = np.mean(summary['false_positive_rates'])\n",
    "                    print(f\"{cell_type:>12}: {total_pixels:>10,} pixels | \"\n",
    "                          f\"False Positive Rate: {100*avg_fp_rate:.2f}%\")\n",
    "            else:\n",
    "                if summary['detection_rates']:\n",
    "                    total_detected = sum(summary['detected_pixels'])\n",
    "                    avg_detection_rate = np.mean(summary['detection_rates'])\n",
    "                    print(f\"{cell_type:>12}: {total_pixels:>10,} pixels | \"\n",
    "                          f\"Detected: {total_detected:>8,} ({100*avg_detection_rate:.2f}%)\")\n",
    "    \n",
    "    # Create performance visualizations\n",
    "    if dice_scores or hausdorff_distances or surface_dice_scores:\n",
    "        create_metrics_plots(dice_scores, hausdorff_distances, surface_dice_scores)\n",
    "    \n",
    "    # Binary confusion matrix analysis\n",
    "    if image_stats:\n",
    "        create_overall_confusion_analysis(image_stats)\n",
    "\n",
    "def create_metrics_plots(dice_scores, hausdorff_distances, surface_dice_scores):\n",
    "    \"\"\"\n",
    "    Create visualization plots for the three main metrics.\n",
    "    \"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    \n",
    "    # Dice Score distribution\n",
    "    if dice_scores:\n",
    "        axes[0].hist(dice_scores, bins=20, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "        axes[0].set_xlabel('Dice Score')\n",
    "        axes[0].set_ylabel('Number of Images')\n",
    "        axes[0].set_title('Distribution of Dice Scores')\n",
    "        axes[0].axvline(np.mean(dice_scores), color='red', linestyle='--', \n",
    "                       label=f'Mean: {np.mean(dice_scores):.3f}')\n",
    "        axes[0].legend()\n",
    "    \n",
    "    # Hausdorff Distance distribution\n",
    "    if hausdorff_distances:\n",
    "        finite_hausdorff = [h for h in hausdorff_distances if not np.isinf(h)]\n",
    "        if finite_hausdorff:\n",
    "            axes[1].hist(finite_hausdorff, bins=20, alpha=0.7, color='lightcoral', edgecolor='black')\n",
    "            axes[1].set_xlabel('Hausdorff Distance')\n",
    "            axes[1].set_ylabel('Number of Images')\n",
    "            axes[1].set_title('Distribution of Hausdorff Distances')\n",
    "            axes[1].axvline(np.mean(finite_hausdorff), color='red', linestyle='--', \n",
    "                           label=f'Mean: {np.mean(finite_hausdorff):.3f}')\n",
    "            axes[1].legend()\n",
    "    \n",
    "    # Surface Dice distribution\n",
    "    if surface_dice_scores:\n",
    "        axes[2].hist(surface_dice_scores, bins=20, alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "        axes[2].set_xlabel('Surface Dice Score')\n",
    "        axes[2].set_ylabel('Number of Images')\n",
    "        axes[2].set_title('Distribution of Surface Dice Scores')\n",
    "        axes[2].axvline(np.mean(surface_dice_scores), color='red', linestyle='--', \n",
    "                       label=f'Mean: {np.mean(surface_dice_scores):.3f}')\n",
    "        axes[2].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def create_overall_confusion_analysis(image_stats):\n",
    "    \"\"\"\n",
    "    Create overall confusion matrix analysis from all processed images.\n",
    "    \"\"\"\n",
    "    all_predictions = []\n",
    "    all_ground_truths = []\n",
    "    \n",
    "    for img_stats in image_stats:\n",
    "        if 'metrics' in img_stats:\n",
    "            # This is a simplified approach - in practice you'd need to store the actual masks\n",
    "            # For now, we'll use the detection rate as a proxy\n",
    "            detection_rate = img_stats['basic_stats']['detection_rate']\n",
    "            # Approximate binary classification based on detection rate\n",
    "            # This is a simplification - ideally you'd store the actual pixel-wise predictions\n",
    "            pass\n",
    "    \n",
    "    print(f\"\\n📋 Overall Performance Summary:\")\n",
    "    print(f\"   Total Images Processed: {len(image_stats)}\")\n",
    "    \n",
    "    # Find best and worst performing images\n",
    "    if any('metrics' in stats for stats in image_stats):\n",
    "        dice_results = [(stats['filename'], stats['metrics']['dice_score']) \n",
    "                       for stats in image_stats if 'metrics' in stats]\n",
    "        \n",
    "        if dice_results:\n",
    "            dice_results.sort(key=lambda x: x[1], reverse=True)\n",
    "            \n",
    "            print(f\"\\n🏆 Best Performing Images (Dice Score):\")\n",
    "            for filename, dice in dice_results[:3]:\n",
    "                print(f\"   • {filename}: {dice:.4f}\")\n",
    "            \n",
    "            print(f\"\\n⚠️  Worst Performing Images (Dice Score):\")\n",
    "            for filename, dice in dice_results[-3:]:\n",
    "                print(f\"   • {filename}: {dice:.4f}\")\n",
    "\n",
    "# Example usage function\n",
    "def run_dbscan_test_example():\n",
    "    \"\"\"\n",
    "    Example of how to run the DBSCAN test with all metrics.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define cell types (adjust according to your dataset)\n",
    "    cell_types = ['Background', 'Type 1', 'Type 2', 'Type 3', 'Type 4', \n",
    "                  'Type 5', 'Type 6', 'Type 7']\n",
    "    \n",
    "    # Run the test\n",
    "    results = test_dbscan_detector(\n",
    "        image_folder=\"/kaggle/input/celldetection/ds1/test/img/cls\",\n",
    "        bin_mask_folder=\"/kaggle/input/celldetection/ds1/test/bin_mask/cls\",\n",
    "        mult_mask_folder=\"/kaggle/input/celldetection/ds1/test/mult_mask/cls\",\n",
    "        color_eps=0.1,\n",
    "        color_min_samples=3,\n",
    "        spatial_eps=0.005,\n",
    "        spatial_min_samples=80,\n",
    "        file_pattern=\"*.tif\",\n",
    "        visualize_samples=3,\n",
    "        cell_types=cell_types\n",
    "    )\n",
    "    \n",
    "    return results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    print(\"DBSCAN Cell Detection with Advanced Metrics\")\n",
    "    run_dbscan_test_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110d7a1a",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-17T07:58:17.722212Z",
     "iopub.status.busy": "2025-06-17T07:58:17.721443Z",
     "iopub.status.idle": "2025-06-17T10:19:03.003325Z",
     "shell.execute_reply": "2025-06-17T10:19:03.002558Z",
     "shell.execute_reply.started": "2025-06-17T07:58:17.722183Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = CellDataSet()\n",
    "model = GrUnetArhitecture()\n",
    "train_model(model, dataset, num_epochs=80,patience=5, grayscale=True,scharr=True, save_path = \"dice_Scharr.pth\")\n",
    "test_detector(dataset, model_class=GrUnetArhitecture, model_path=\"dice_Scharr.pth\", grayscale=True,scharr=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8cabb6",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-17T11:50:14.267622Z",
     "iopub.status.busy": "2025-06-17T11:50:14.267332Z",
     "iopub.status.idle": "2025-06-17T11:52:40.507027Z",
     "shell.execute_reply": "2025-06-17T11:52:40.505935Z",
     "shell.execute_reply.started": "2025-06-17T11:50:14.267599Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = CellDataSet()\n",
    "test_detector(dataset, model_class=GrayScaleMediumUnet, model_path=\"dice_mediumScharr.pth\", grayscale=True,scharr=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4a9424",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-17T11:53:02.084340Z",
     "iopub.status.busy": "2025-06-17T11:53:02.084016Z",
     "iopub.status.idle": "2025-06-17T11:56:24.700691Z",
     "shell.execute_reply": "2025-06-17T11:56:24.699841Z",
     "shell.execute_reply.started": "2025-06-17T11:53:02.084317Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_detector(dataset, model_class=GrUnetArhitecture, model_path=\"dice_Scharr.pth\", grayscale=True,scharr=True)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7460948,
     "sourceId": 11872164,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6.150025,
   "end_time": "2025-06-18T20:10:35.613911",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-18T20:10:29.463886",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
